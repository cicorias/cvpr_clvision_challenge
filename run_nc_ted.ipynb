{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-1-25fe0f35320c>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-1-25fe0f35320c>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    ./naive_baseline.py --scenario=\"nic\" --sub_dir=\"nic\"\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "./naive_baseline.py --scenario=\"nic\" --sub_dir=\"nic\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available kernels:\n",
      "  python3            /data/anaconda/envs/py36/share/jupyter/kernels/python3\n",
      "  ir                 /usr/local/share/jupyter/kernels/ir\n",
      "  julia-1.2          /usr/local/share/jupyter/kernels/julia-1.2\n",
      "  pysparkkernel      /usr/local/share/jupyter/kernels/pysparkkernel\n",
      "  python2            /usr/local/share/jupyter/kernels/python2\n",
      "  python3-azureml    /usr/local/share/jupyter/kernels/python3-azureml\n",
      "  python3-mls        /usr/local/share/jupyter/kernels/python3-mls\n",
      "  spark-3-python     /usr/local/share/jupyter/kernels/spark-3-python\n",
      "  spark-python       /usr/local/share/jupyter/kernels/spark-python\n",
      "  sparkkernel        /usr/local/share/jupyter/kernels/sparkkernel\n",
      "  sparkrkernel       /usr/local/share/jupyter/kernels/sparkrkernel\n"
     ]
    }
   ],
   "source": [
    "!jupyter kernelspec list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 16\n",
      "drwxr-xr-x 13 root root 4096 Nov  5  2019 ..\n",
      "drwxr-xr-x  2 root root 4096 Nov  5  2019 .\n",
      "-rw-r--r--  1 root root  186 Nov  5  2019 kernel.json\n",
      "-rw-r--r--  1 root root  103 Nov  5  2019 kernel.sh\n"
     ]
    }
   ],
   "source": [
    "!ls -alt /usr/local/share/jupyter/kernels/python3-azureml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.6.9 :: Anaconda, Inc.\n"
     ]
    }
   ],
   "source": [
    "!python -V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(batch_size=32, classifier='ResNet18', cuda=True, device='cuda:0', epochs=1, input_size=[3, 128, 128], lr=0.01, n_classes=50, preload_data=True, replay_examples=0, scenario='multi-task-nc', sub_dir='multi-task-nc')\n",
      "\n",
      "Loading data...\n",
      "Loading paths...\n",
      "Loading LUP...\n",
      "Loading labels...\n",
      "preparing CL benchmark...\n",
      "Recovering validation set...\n",
      "----------- batch 0 -------------\n",
      "x shape: (23980, 128, 128, 3), y shape: (23980,)\n",
      "Task Label:  0\n",
      "training ep:  0\n",
      "==>>> it: 0, avg. loss: 0.133207, running train acc: 0.031\n",
      "==>>> it: 100, avg. loss: 0.000037, running train acc: 0.853\n",
      "==>>> it: 200, avg. loss: 0.000012, running train acc: 0.919\n",
      "==>>> it: 300, avg. loss: 0.000007, running train acc: 0.944\n",
      "==>>> it: 400, avg. loss: 0.000004, running train acc: 0.957\n",
      "==>>> it: 500, avg. loss: 0.000002, running train acc: 0.965\n",
      "==>>> it: 600, avg. loss: 0.000000, running train acc: 0.970\n",
      "==>>> it: 700, avg. loss: 0.000001, running train acc: 0.974\n",
      "------------------------------------------\n",
      "Avg. acc: [0.10617283950617284]\n",
      "------------------------------------------\n",
      "----------- batch 1 -------------\n",
      "x shape: (11993, 128, 128, 3), y shape: (11993,)\n",
      "Task Label:  1\n",
      "training ep:  0\n",
      "==>>> it: 0, avg. loss: 0.122251, running train acc: 0.000\n",
      "==>>> it: 100, avg. loss: 0.000008, running train acc: 0.959\n",
      "==>>> it: 200, avg. loss: 0.000004, running train acc: 0.979\n",
      "==>>> it: 300, avg. loss: 0.000005, running train acc: 0.985\n",
      "------------------------------------------\n",
      "Avg. acc: [0.2108641975308642]\n",
      "------------------------------------------\n",
      "----------- batch 2 -------------\n",
      "x shape: (11990, 128, 128, 3), y shape: (11990,)\n",
      "Task Label:  2\n",
      "training ep:  0\n",
      "==>>> it: 0, avg. loss: 0.122251, running train acc: 0.000\n",
      "==>>> it: 100, avg. loss: 0.000020, running train acc: 0.949\n",
      "==>>> it: 200, avg. loss: 0.000027, running train acc: 0.971\n",
      "==>>> it: 300, avg. loss: 0.000000, running train acc: 0.980\n",
      "------------------------------------------\n",
      "Avg. acc: [0.31209876543209875]\n",
      "------------------------------------------\n",
      "----------- batch 3 -------------\n",
      "x shape: (11993, 128, 128, 3), y shape: (11993,)\n",
      "Task Label:  3\n",
      "training ep:  0\n",
      "==>>> it: 0, avg. loss: 0.122251, running train acc: 0.000\n",
      "==>>> it: 100, avg. loss: 0.000012, running train acc: 0.972\n",
      "==>>> it: 200, avg. loss: 0.000002, running train acc: 0.984\n",
      "==>>> it: 300, avg. loss: 0.000001, running train acc: 0.988\n",
      "------------------------------------------\n",
      "Avg. acc: [0.4150617283950618]\n",
      "------------------------------------------\n",
      "----------- batch 4 -------------\n",
      "x shape: (11989, 128, 128, 3), y shape: (11989,)\n",
      "Task Label:  4\n",
      "training ep:  0\n",
      "==>>> it: 0, avg. loss: 0.122251, running train acc: 0.000\n",
      "==>>> it: 100, avg. loss: 0.000039, running train acc: 0.933\n",
      "==>>> it: 200, avg. loss: 0.000002, running train acc: 0.964\n",
      "==>>> it: 300, avg. loss: 0.000001, running train acc: 0.974\n",
      "------------------------------------------\n",
      "Avg. acc: [0.5259259259259259]\n",
      "------------------------------------------\n",
      "----------- batch 5 -------------\n",
      "x shape: (11979, 128, 128, 3), y shape: (11979,)\n",
      "Task Label:  5\n",
      "training ep:  0\n",
      "==>>> it: 0, avg. loss: 0.122251, running train acc: 0.000\n",
      "==>>> it: 100, avg. loss: 0.000115, running train acc: 0.946\n",
      "==>>> it: 200, avg. loss: 0.000004, running train acc: 0.967\n",
      "==>>> it: 300, avg. loss: 0.000003, running train acc: 0.976\n",
      "------------------------------------------\n",
      "Avg. acc: [0.6293827160493827]\n",
      "------------------------------------------\n",
      "----------- batch 6 -------------\n",
      "x shape: (11990, 128, 128, 3), y shape: (11990,)\n",
      "Task Label:  6\n",
      "training ep:  0\n",
      "==>>> it: 0, avg. loss: 0.122251, running train acc: 0.000\n",
      "==>>> it: 100, avg. loss: 0.000057, running train acc: 0.967\n",
      "==>>> it: 200, avg. loss: 0.000005, running train acc: 0.980\n",
      "==>>> it: 300, avg. loss: 0.000000, running train acc: 0.986\n",
      "------------------------------------------\n",
      "Avg. acc: [0.7335802469135803]\n",
      "------------------------------------------\n",
      "----------- batch 7 -------------\n",
      "x shape: (11987, 128, 128, 3), y shape: (11987,)\n",
      "Task Label:  7\n",
      "training ep:  0\n",
      "==>>> it: 0, avg. loss: 0.122251, running train acc: 0.000\n",
      "==>>> it: 100, avg. loss: 0.000012, running train acc: 0.963\n",
      "==>>> it: 200, avg. loss: 0.000007, running train acc: 0.980\n",
      "==>>> it: 300, avg. loss: 0.000000, running train acc: 0.987\n",
      "------------------------------------------\n",
      "Avg. acc: [0.8217283950617283]\n",
      "------------------------------------------\n",
      "----------- batch 8 -------------\n",
      "x shape: (11993, 128, 128, 3), y shape: (11993,)\n",
      "Task Label:  8\n",
      "training ep:  0\n",
      "==>>> it: 0, avg. loss: 0.122251, running train acc: 0.000\n",
      "==>>> it: 100, avg. loss: 0.000016, running train acc: 0.975\n",
      "==>>> it: 200, avg. loss: 0.000005, running train acc: 0.986\n",
      "==>>> it: 300, avg. loss: 0.000001, running train acc: 0.990\n",
      "------------------------------------------\n",
      "Avg. acc: [0.9306172839506173]\n",
      "------------------------------------------\n",
      "Training Time: 9.756543401877085m\n",
      "Final inference on test set...\n",
      "Experiment completed.\n",
      "time for multi-task-nc: 0:11:21.654674\n",
      "total time: 0:11:21.655397\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "startTime = datetime.now()\n",
    "\n",
    "# scenarios = ['ni', 'multi-task-nc', 'nic']\n",
    "scenarios = ['multi-task-nc']\n",
    "\n",
    "for s in scenarios:\n",
    "    !python ./naive_baseline.py --scenario=\"{s}\" --sub_dir=\"{s}\" -cls=\"ResNet18\"\n",
    "    print('time for {}: {}'.format(s, datetime.now() - startTime))\n",
    "    \n",
    "print('total time: {}'.format(datetime.now() - startTime))\n",
    "\n",
    "# Naive Baseline NC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(batch_size=32, classifier='ResNet34', cuda=True, device='cuda:0', dropout=0.0, epochs=1, input_size=[3, 128, 128], lr=0.01, n_classes=50, preload_data=True, replay_examples=0, scenario='multi-task-nc', sub_dir='multi-task-nc')\n",
      "\n",
      "Loading data...\n",
      "Loading paths...\n",
      "Loading LUP...\n",
      "Loading labels...\n",
      "preparing CL benchmark...\n",
      "Recovering validation set...\n",
      "----------- batch 0 -------------\n",
      "x shape: (23980, 128, 128, 3), y shape: (23980,)\n",
      "Task Label:  0\n",
      "training ep:  0\n",
      "==>>> it: 0, avg. loss: 0.129180, running train acc: 0.000\n",
      "==>>> it: 100, avg. loss: 0.000037, running train acc: 0.861\n",
      "==>>> it: 200, avg. loss: 0.000007, running train acc: 0.925\n",
      "==>>> it: 300, avg. loss: 0.000002, running train acc: 0.948\n",
      "==>>> it: 400, avg. loss: 0.000000, running train acc: 0.960\n",
      "==>>> it: 500, avg. loss: 0.000001, running train acc: 0.968\n",
      "==>>> it: 600, avg. loss: 0.000000, running train acc: 0.973\n",
      "==>>> it: 700, avg. loss: 0.000000, running train acc: 0.976\n",
      "------------------------------------------\n",
      "Avg. acc: [0.10641975308641975]\n",
      "------------------------------------------\n",
      "----------- batch 1 -------------\n",
      "x shape: (11993, 128, 128, 3), y shape: (11993,)\n",
      "Task Label:  1\n",
      "training ep:  0\n",
      "==>>> it: 0, avg. loss: 0.122251, running train acc: 0.000\n",
      "==>>> it: 100, avg. loss: 0.000022, running train acc: 0.953\n",
      "==>>> it: 200, avg. loss: 0.000003, running train acc: 0.975\n",
      "==>>> it: 300, avg. loss: 0.000002, running train acc: 0.983\n",
      "------------------------------------------\n",
      "Avg. acc: [0.21481481481481482]\n",
      "------------------------------------------\n",
      "----------- batch 2 -------------\n",
      "x shape: (11990, 128, 128, 3), y shape: (11990,)\n",
      "Task Label:  2\n",
      "training ep:  0\n",
      "==>>> it: 0, avg. loss: 0.122251, running train acc: 0.000\n",
      "==>>> it: 100, avg. loss: 0.000015, running train acc: 0.952\n",
      "==>>> it: 200, avg. loss: 0.000001, running train acc: 0.973\n",
      "==>>> it: 300, avg. loss: 0.000000, running train acc: 0.981\n",
      "------------------------------------------\n",
      "Avg. acc: [0.31975308641975314]\n",
      "------------------------------------------\n",
      "----------- batch 3 -------------\n",
      "x shape: (11993, 128, 128, 3), y shape: (11993,)\n",
      "Task Label:  3\n",
      "training ep:  0\n",
      "==>>> it: 0, avg. loss: 0.122251, running train acc: 0.000\n",
      "==>>> it: 100, avg. loss: 0.000004, running train acc: 0.976\n",
      "==>>> it: 200, avg. loss: 0.000001, running train acc: 0.985\n",
      "==>>> it: 300, avg. loss: 0.000001, running train acc: 0.989\n",
      "------------------------------------------\n",
      "Avg. acc: [0.42987654320987656]\n",
      "------------------------------------------\n",
      "----------- batch 4 -------------\n",
      "x shape: (11989, 128, 128, 3), y shape: (11989,)\n",
      "Task Label:  4\n",
      "training ep:  0\n",
      "==>>> it: 0, avg. loss: 0.122251, running train acc: 0.000\n",
      "==>>> it: 100, avg. loss: 0.000005, running train acc: 0.942\n",
      "==>>> it: 200, avg. loss: 0.000001, running train acc: 0.966\n",
      "==>>> it: 300, avg. loss: 0.000001, running train acc: 0.976\n",
      "------------------------------------------\n",
      "Avg. acc: [0.5328395061728395]\n",
      "------------------------------------------\n",
      "----------- batch 5 -------------\n",
      "x shape: (11979, 128, 128, 3), y shape: (11979,)\n",
      "Task Label:  5\n",
      "training ep:  0\n",
      "==>>> it: 0, avg. loss: 0.122251, running train acc: 0.000\n",
      "==>>> it: 100, avg. loss: 0.000034, running train acc: 0.961\n",
      "==>>> it: 200, avg. loss: 0.000001, running train acc: 0.974\n",
      "==>>> it: 300, avg. loss: 0.000000, running train acc: 0.981\n",
      "------------------------------------------\n",
      "Avg. acc: [0.6343209876543211]\n",
      "------------------------------------------\n",
      "----------- batch 6 -------------\n",
      "x shape: (11990, 128, 128, 3), y shape: (11990,)\n",
      "Task Label:  6\n",
      "training ep:  0\n",
      "==>>> it: 0, avg. loss: 0.122251, running train acc: 0.000\n",
      "==>>> it: 100, avg. loss: 0.000012, running train acc: 0.966\n",
      "==>>> it: 200, avg. loss: 0.000001, running train acc: 0.980\n",
      "==>>> it: 300, avg. loss: 0.000000, running train acc: 0.986\n",
      "------------------------------------------\n",
      "Avg. acc: [0.7375308641975309]\n",
      "------------------------------------------\n",
      "----------- batch 7 -------------\n",
      "x shape: (11987, 128, 128, 3), y shape: (11987,)\n",
      "Task Label:  7\n",
      "training ep:  0\n",
      "==>>> it: 0, avg. loss: 0.122251, running train acc: 0.000\n",
      "==>>> it: 100, avg. loss: 0.000012, running train acc: 0.962\n",
      "==>>> it: 200, avg. loss: 0.000001, running train acc: 0.980\n",
      "==>>> it: 300, avg. loss: 0.000001, running train acc: 0.986\n",
      "------------------------------------------\n",
      "Avg. acc: [0.8182716049382717]\n",
      "------------------------------------------\n",
      "----------- batch 8 -------------\n",
      "x shape: (11993, 128, 128, 3), y shape: (11993,)\n",
      "Task Label:  8\n",
      "training ep:  0\n",
      "==>>> it: 0, avg. loss: 0.122251, running train acc: 0.000\n",
      "==>>> it: 100, avg. loss: 0.000007, running train acc: 0.972\n",
      "==>>> it: 200, avg. loss: 0.000013, running train acc: 0.984\n",
      "==>>> it: 300, avg. loss: 0.000000, running train acc: 0.988\n",
      "------------------------------------------\n",
      "Avg. acc: [0.9251851851851851]\n",
      "------------------------------------------\n",
      "Training Time: 15.338896238803864m\n",
      "Final inference on test set...\n",
      "Experiment completed.\n",
      "time for multi-task-nc: 0:17:21.402313\n",
      "total time: 0:17:21.402592\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "startTime = datetime.now()\n",
    "\n",
    "# scenarios = ['ni', 'multi-task-nc', 'nic']\n",
    "scenarios = ['multi-task-nc']\n",
    "\n",
    "for s in scenarios:\n",
    "    !python ./naive_baseline_ted.py --scenario=\"{s}\" --sub_dir=\"{s}\" -cls=\"ResNet34\"\n",
    "    print('time for {}: {}'.format(s, datetime.now() - startTime))\n",
    "    \n",
    "print('total time: {}'.format(datetime.now() - startTime))\n",
    "\n",
    "# Basic ResNet34"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(batch_size=32, classifier='ResNet18', cuda=True, device='cuda:0', dropout=0.4, epochs=1, input_size=[3, 128, 128], lr=0.01, n_classes=50, preload_data=True, replay_examples=0, scenario='multi-task-nc', sub_dir='multi-task-nc')\n",
      "\n",
      "Loading data...\n",
      "Loading paths...\n",
      "Loading LUP...\n",
      "Loading labels...\n",
      "preparing CL benchmark...\n",
      "Recovering validation set...\n",
      "Using Dropout of 0.4\n",
      "----------- batch 0 -------------\n",
      "x shape: (23980, 128, 128, 3), y shape: (23980,)\n",
      "Task Label:  0\n",
      "training ep:  0\n",
      "==>>> it: 0, avg. loss: 0.129850, running train acc: 0.062\n",
      "==>>> it: 100, avg. loss: 0.000233, running train acc: 0.428\n",
      "==>>> it: 200, avg. loss: 0.000035, running train acc: 0.651\n",
      "==>>> it: 300, avg. loss: 0.000021, running train acc: 0.749\n",
      "==>>> it: 400, avg. loss: 0.000005, running train acc: 0.806\n",
      "==>>> it: 500, avg. loss: 0.000003, running train acc: 0.840\n",
      "==>>> it: 600, avg. loss: 0.000000, running train acc: 0.864\n",
      "==>>> it: 700, avg. loss: 0.000006, running train acc: 0.882\n",
      "------------------------------------------\n",
      "Avg. acc: [0.10444444444444444]\n",
      "------------------------------------------\n",
      "----------- batch 1 -------------\n",
      "x shape: (11993, 128, 128, 3), y shape: (11993,)\n",
      "Task Label:  1\n",
      "training ep:  0\n",
      "==>>> it: 0, avg. loss: 0.321763, running train acc: 0.000\n",
      "==>>> it: 100, avg. loss: 0.000038, running train acc: 0.828\n",
      "==>>> it: 200, avg. loss: 0.000010, running train acc: 0.908\n",
      "==>>> it: 300, avg. loss: 0.000002, running train acc: 0.936\n",
      "------------------------------------------\n",
      "Avg. acc: [0.10567901234567902]\n",
      "------------------------------------------\n",
      "----------- batch 2 -------------\n",
      "x shape: (11990, 128, 128, 3), y shape: (11990,)\n",
      "Task Label:  2\n",
      "training ep:  0\n",
      "==>>> it: 0, avg. loss: 0.384161, running train acc: 0.000\n",
      "==>>> it: 100, avg. loss: 0.000019, running train acc: 0.819\n",
      "==>>> it: 200, avg. loss: 0.000008, running train acc: 0.897\n",
      "==>>> it: 300, avg. loss: 0.000007, running train acc: 0.927\n",
      "------------------------------------------\n",
      "Avg. acc: [0.10518518518518519]\n",
      "------------------------------------------\n",
      "----------- batch 3 -------------\n",
      "x shape: (11993, 128, 128, 3), y shape: (11993,)\n",
      "Task Label:  3\n",
      "training ep:  0\n",
      "==>>> it: 0, avg. loss: 0.375889, running train acc: 0.000\n",
      "==>>> it: 100, avg. loss: 0.000013, running train acc: 0.858\n",
      "==>>> it: 200, avg. loss: 0.000020, running train acc: 0.922\n",
      "==>>> it: 300, avg. loss: 0.000000, running train acc: 0.946\n",
      "------------------------------------------\n",
      "Avg. acc: [0.10864197530864199]\n",
      "------------------------------------------\n",
      "----------- batch 4 -------------\n",
      "x shape: (11989, 128, 128, 3), y shape: (11989,)\n",
      "Task Label:  4\n",
      "training ep:  0\n",
      "==>>> it: 0, avg. loss: 0.346484, running train acc: 0.000\n",
      "==>>> it: 100, avg. loss: 0.000009, running train acc: 0.764\n",
      "==>>> it: 200, avg. loss: 0.000005, running train acc: 0.871\n",
      "==>>> it: 100, avg. loss: 0.000022, running train acc: 0.823\n",
      "==>>> it: 200, avg. loss: 0.000024, running train acc: 0.901\n",
      "==>>> it: 300, avg. loss: 0.000003, running train acc: 0.930\n",
      "------------------------------------------\n",
      "Avg. acc: [0.11851851851851852]\n",
      "------------------------------------------\n",
      "----------- batch 6 -------------\n",
      "x shape: (11990, 128, 128, 3), y shape: (11990,)\n",
      "Task Label:  6\n",
      "training ep:  0\n",
      "==>>> it: 0, avg. loss: 0.479682, running train acc: 0.000\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "startTime = datetime.now()\n",
    "\n",
    "# scenarios = ['ni', 'multi-task-nc', 'nic']\n",
    "scenarios = ['multi-task-nc']\n",
    "\n",
    "for s in scenarios:\n",
    "    !python ./naive_baseline_ted.py --scenario=\"{s}\" --sub_dir=\"{s}\" -cls=\"ResNet18\" -dp=0.4\n",
    "    print('time for {}: {}'.format(s, datetime.now() - startTime))\n",
    "    \n",
    "print('total time: {}'.format(datetime.now() - startTime))\n",
    "\n",
    "# Basic ResNet18 with 0.4 dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(batch_size=32, classifier='ResNet34', cuda=True, device='cuda:0', epochs=3, input_size=[3, 128, 128], lr=0.01, n_classes=50, preload_data=True, replay_examples=150, scenario='ni', sub_dir='ni')\n",
      "\n",
      "Loading data...\n",
      "Loading paths...\n",
      "Loading LUP...\n",
      "Loading labels...\n",
      "preparing CL benchmark...\n",
      "Recovering validation set...\n",
      "----------- batch 0 -------------\n",
      "x shape: (15141, 128, 128, 3), y shape: (15141,)\n",
      "Task Label:  0\n",
      "training ep:  0\n",
      "==>>> it: 0, avg. loss: 0.129192, running train acc: 0.000\n",
      "==>>> it: 100, avg. loss: 0.000254, running train acc: 0.627\n",
      "==>>> it: 200, avg. loss: 0.000045, running train acc: 0.779\n",
      "==>>> it: 300, avg. loss: 0.000016, running train acc: 0.846\n",
      "==>>> it: 400, avg. loss: 0.000009, running train acc: 0.882\n",
      "training ep:  1\n",
      "==>>> it: 0, avg. loss: 0.002116, running train acc: 1.000\n",
      "==>>> it: 100, avg. loss: 0.000013, running train acc: 0.998\n",
      "==>>> it: 200, avg. loss: 0.000004, running train acc: 0.999\n",
      "==>>> it: 300, avg. loss: 0.000003, running train acc: 0.999\n",
      "==>>> it: 400, avg. loss: 0.000002, running train acc: 0.999\n",
      "training ep:  2\n",
      "==>>> it: 0, avg. loss: 0.000506, running train acc: 1.000\n",
      "==>>> it: 100, avg. loss: 0.000004, running train acc: 1.000\n",
      "==>>> it: 200, avg. loss: 0.000002, running train acc: 1.000\n",
      "==>>> it: 300, avg. loss: 0.000001, running train acc: 1.000\n",
      "==>>> it: 400, avg. loss: 0.000001, running train acc: 1.000\n",
      "------------------------------------------\n",
      "Avg. acc: [0.4788795020008893]\n",
      "------------------------------------------\n",
      "----------- batch 1 -------------\n",
      "x shape: (15295, 128, 128, 3), y shape: (15295,)\n",
      "Task Label:  0\n",
      "training ep:  0\n",
      "==>>> it: 0, avg. loss: 0.040080, running train acc: 0.656\n",
      "==>>> it: 100, avg. loss: 0.000065, running train acc: 0.917\n",
      "==>>> it: 200, avg. loss: 0.000005, running train acc: 0.951\n",
      "==>>> it: 300, avg. loss: 0.000005, running train acc: 0.964\n",
      "==>>> it: 400, avg. loss: 0.000001, running train acc: 0.972\n",
      "training ep:  1\n",
      "==>>> it: 0, avg. loss: 0.000492, running train acc: 1.000\n",
      "==>>> it: 100, avg. loss: 0.000002, running train acc: 1.000\n",
      "==>>> it: 200, avg. loss: 0.000002, running train acc: 1.000\n",
      "==>>> it: 300, avg. loss: 0.000001, running train acc: 1.000\n",
      "==>>> it: 400, avg. loss: 0.000000, running train acc: 1.000\n",
      "training ep:  2\n",
      "==>>> it: 0, avg. loss: 0.000175, running train acc: 1.000\n",
      "==>>> it: 100, avg. loss: 0.000001, running train acc: 1.000\n",
      "==>>> it: 200, avg. loss: 0.000001, running train acc: 1.000\n",
      "==>>> it: 300, avg. loss: 0.000001, running train acc: 1.000\n",
      "==>>> it: 400, avg. loss: 0.000000, running train acc: 1.000\n",
      "------------------------------------------\n",
      "Avg. acc: [0.5762561138283682]\n",
      "------------------------------------------\n",
      "----------- batch 2 -------------\n",
      "x shape: (15436, 128, 128, 3), y shape: (15436,)\n",
      "Task Label:  0\n",
      "training ep:  0\n",
      "==>>> it: 0, avg. loss: 0.023047, running train acc: 0.812\n",
      "==>>> it: 100, avg. loss: 0.000063, running train acc: 0.927\n",
      "==>>> it: 200, avg. loss: 0.000003, running train acc: 0.956\n",
      "==>>> it: 300, avg. loss: 0.000004, running train acc: 0.969\n",
      "==>>> it: 400, avg. loss: 0.000007, running train acc: 0.975\n",
      "training ep:  1\n",
      "==>>> it: 0, avg. loss: 0.000344, running train acc: 1.000\n",
      "==>>> it: 100, avg. loss: 0.000002, running train acc: 1.000\n",
      "==>>> it: 200, avg. loss: 0.000001, running train acc: 1.000\n",
      "==>>> it: 300, avg. loss: 0.000000, running train acc: 1.000\n",
      "==>>> it: 400, avg. loss: 0.000001, running train acc: 1.000\n",
      "training ep:  2\n",
      "==>>> it: 0, avg. loss: 0.000141, running train acc: 1.000\n",
      "==>>> it: 100, avg. loss: 0.000001, running train acc: 1.000\n",
      "==>>> it: 200, avg. loss: 0.000001, running train acc: 1.000\n",
      "==>>> it: 300, avg. loss: 0.000000, running train acc: 1.000\n",
      "==>>> it: 400, avg. loss: 0.000000, running train acc: 1.000\n",
      "------------------------------------------\n",
      "Avg. acc: [0.7003112494441974]\n",
      "------------------------------------------\n",
      "----------- batch 3 -------------\n",
      "x shape: (15594, 128, 128, 3), y shape: (15594,)\n",
      "Task Label:  0\n",
      "training ep:  0\n",
      "==>>> it: 0, avg. loss: 0.024031, running train acc: 0.812\n",
      "==>>> it: 100, avg. loss: 0.000019, running train acc: 0.927\n",
      "==>>> it: 200, avg. loss: 0.000004, running train acc: 0.952\n",
      "==>>> it: 300, avg. loss: 0.000001, running train acc: 0.964\n",
      "==>>> it: 400, avg. loss: 0.000006, running train acc: 0.971\n",
      "training ep:  1\n",
      "==>>> it: 0, avg. loss: 0.001023, running train acc: 1.000\n",
      "==>>> it: 100, avg. loss: 0.000001, running train acc: 1.000\n",
      "==>>> it: 200, avg. loss: 0.000001, running train acc: 1.000\n",
      "==>>> it: 300, avg. loss: 0.000000, running train acc: 1.000\n",
      "==>>> it: 400, avg. loss: 0.000000, running train acc: 1.000\n",
      "training ep:  2\n",
      "==>>> it: 0, avg. loss: 0.000130, running train acc: 1.000\n",
      "==>>> it: 100, avg. loss: 0.000001, running train acc: 1.000\n",
      "==>>> it: 200, avg. loss: 0.000001, running train acc: 1.000\n",
      "==>>> it: 300, avg. loss: 0.000000, running train acc: 1.000\n",
      "==>>> it: 400, avg. loss: 0.000000, running train acc: 1.000\n",
      "------------------------------------------\n",
      "Avg. acc: [0.7025344597598933]\n",
      "------------------------------------------\n",
      "----------- batch 4 -------------\n",
      "x shape: (15739, 128, 128, 3), y shape: (15739,)\n",
      "Task Label:  0\n",
      "training ep:  0\n",
      "==>>> it: 0, avg. loss: 0.004858, running train acc: 0.969\n",
      "==>>> it: 100, avg. loss: 0.000048, running train acc: 0.946\n",
      "==>>> it: 200, avg. loss: 0.000021, running train acc: 0.966\n",
      "==>>> it: 300, avg. loss: 0.000001, running train acc: 0.975\n",
      "==>>> it: 400, avg. loss: 0.000002, running train acc: 0.980\n",
      "training ep:  1\n",
      "==>>> it: 0, avg. loss: 0.000169, running train acc: 1.000\n",
      "==>>> it: 100, avg. loss: 0.000004, running train acc: 1.000\n",
      "==>>> it: 200, avg. loss: 0.000001, running train acc: 1.000\n",
      "==>>> it: 300, avg. loss: 0.000000, running train acc: 1.000\n",
      "==>>> it: 400, avg. loss: 0.000001, running train acc: 1.000\n",
      "training ep:  2\n",
      "==>>> it: 0, avg. loss: 0.000071, running train acc: 1.000\n",
      "==>>> it: 100, avg. loss: 0.000002, running train acc: 1.000\n",
      "==>>> it: 200, avg. loss: 0.000001, running train acc: 1.000\n",
      "==>>> it: 300, avg. loss: 0.000000, running train acc: 1.000\n",
      "==>>> it: 400, avg. loss: 0.000000, running train acc: 1.000\n",
      "------------------------------------------\n",
      "Avg. acc: [0.7256558470431302]\n",
      "------------------------------------------\n",
      "----------- batch 5 -------------\n",
      "x shape: (15889, 128, 128, 3), y shape: (15889,)\n",
      "Task Label:  0\n",
      "training ep:  0\n",
      "==>>> it: 0, avg. loss: 0.040417, running train acc: 0.594\n",
      "==>>> it: 100, avg. loss: 0.000053, running train acc: 0.922\n",
      "==>>> it: 200, avg. loss: 0.000017, running train acc: 0.951\n",
      "==>>> it: 300, avg. loss: 0.000001, running train acc: 0.964\n",
      "==>>> it: 400, avg. loss: 0.000005, running train acc: 0.972\n",
      "training ep:  1\n",
      "==>>> it: 0, avg. loss: 0.000530, running train acc: 1.000\n",
      "==>>> it: 100, avg. loss: 0.000002, running train acc: 0.998\n",
      "==>>> it: 200, avg. loss: 0.000001, running train acc: 0.999\n",
      "==>>> it: 300, avg. loss: 0.000000, running train acc: 0.999\n",
      "==>>> it: 400, avg. loss: 0.000000, running train acc: 1.000\n",
      "training ep:  2\n",
      "==>>> it: 0, avg. loss: 0.000125, running train acc: 1.000\n",
      "==>>> it: 100, avg. loss: 0.000001, running train acc: 1.000\n",
      "==>>> it: 200, avg. loss: 0.000000, running train acc: 1.000\n",
      "==>>> it: 300, avg. loss: 0.000000, running train acc: 1.000\n",
      "==>>> it: 400, avg. loss: 0.000000, running train acc: 1.000\n",
      "------------------------------------------\n",
      "Avg. acc: [0.7492218763895064]\n",
      "------------------------------------------\n",
      "----------- batch 6 -------------\n",
      "x shape: (16016, 128, 128, 3), y shape: (16016,)\n",
      "Task Label:  0\n",
      "training ep:  0\n",
      "==>>> it: 0, avg. loss: 0.016548, running train acc: 0.844\n",
      "==>>> it: 100, avg. loss: 0.000040, running train acc: 0.959\n",
      "==>>> it: 200, avg. loss: 0.000001, running train acc: 0.975\n",
      "==>>> it: 300, avg. loss: 0.000001, running train acc: 0.982\n",
      "==>>> it: 400, avg. loss: 0.000002, running train acc: 0.985\n",
      "==>>> it: 500, avg. loss: 0.000000, running train acc: 0.987\n",
      "training ep:  1\n",
      "==>>> it: 0, avg. loss: 0.000289, running train acc: 1.000\n",
      "==>>> it: 100, avg. loss: 0.000001, running train acc: 0.999\n",
      "==>>> it: 200, avg. loss: 0.000001, running train acc: 1.000\n",
      "==>>> it: 300, avg. loss: 0.000000, running train acc: 1.000\n",
      "==>>> it: 400, avg. loss: 0.000000, running train acc: 1.000\n",
      "==>>> it: 500, avg. loss: 0.000000, running train acc: 1.000\n",
      "training ep:  2\n",
      "==>>> it: 0, avg. loss: 0.000051, running train acc: 1.000\n",
      "==>>> it: 100, avg. loss: 0.000001, running train acc: 1.000\n",
      "==>>> it: 200, avg. loss: 0.000000, running train acc: 1.000\n",
      "==>>> it: 300, avg. loss: 0.000000, running train acc: 1.000\n",
      "==>>> it: 400, avg. loss: 0.000000, running train acc: 1.000\n",
      "==>>> it: 500, avg. loss: 0.000000, running train acc: 1.000\n",
      "------------------------------------------\n",
      "Avg. acc: [0.7714539795464651]\n",
      "------------------------------------------\n",
      "----------- batch 7 -------------\n",
      "x shape: (16184, 128, 128, 3), y shape: (16184,)\n",
      "Task Label:  0\n",
      "training ep:  0\n",
      "==>>> it: 0, avg. loss: 0.009849, running train acc: 0.906\n",
      "==>>> it: 100, avg. loss: 0.000045, running train acc: 0.948\n",
      "==>>> it: 200, avg. loss: 0.000004, running train acc: 0.962\n",
      "==>>> it: 300, avg. loss: 0.000008, running train acc: 0.968\n",
      "==>>> it: 400, avg. loss: 0.000001, running train acc: 0.975\n",
      "==>>> it: 500, avg. loss: 0.000000, running train acc: 0.978\n",
      "training ep:  1\n",
      "==>>> it: 0, avg. loss: 0.000291, running train acc: 1.000\n",
      "==>>> it: 100, avg. loss: 0.000002, running train acc: 0.999\n",
      "==>>> it: 200, avg. loss: 0.000000, running train acc: 1.000\n",
      "==>>> it: 300, avg. loss: 0.000000, running train acc: 1.000\n",
      "==>>> it: 400, avg. loss: 0.000000, running train acc: 1.000\n",
      "==>>> it: 500, avg. loss: 0.000000, running train acc: 1.000\n",
      "training ep:  2\n",
      "==>>> it: 0, avg. loss: 0.000057, running train acc: 1.000\n",
      "==>>> it: 100, avg. loss: 0.000001, running train acc: 1.000\n",
      "==>>> it: 200, avg. loss: 0.000000, running train acc: 1.000\n",
      "==>>> it: 300, avg. loss: 0.000000, running train acc: 1.000\n",
      "==>>> it: 400, avg. loss: 0.000000, running train acc: 1.000\n",
      "==>>> it: 500, avg. loss: 0.000000, running train acc: 1.000\n",
      "------------------------------------------\n",
      "Avg. acc: [0.7910182303245887]\n",
      "------------------------------------------\n",
      "Training Time: 44.026807912190755m\n",
      "Final inference on test set...\n",
      "Experiment completed.\n",
      "time for ni: 0:45:51.746006\n",
      "total time: 0:45:51.746258\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "startTime = datetime.now()\n",
    "\n",
    "# scenarios = ['ni', 'multi-task-nc', 'nic']\n",
    "scenarios = ['ni']\n",
    "\n",
    "for s in scenarios:\n",
    "    !python ./naive_baseline.py --scenario=\"{s}\" --sub_dir=\"{s}\" -cls=\"ResNet34\" --replay_examples=150 --epochs=3\n",
    "    print('time for {}: {}'.format(s, datetime.now() - startTime))\n",
    "    \n",
    "print('total time: {}'.format(datetime.now() - startTime))\n",
    "\n",
    "# Basic ResNet34 with 150 replay "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(batch_size=32, classifier='ResNet34', cuda=True, device='cuda:0', dropout=0.5, epochs=2, input_size=[3, 128, 128], lr=0.01, n_classes=50, preload_data=True, replay_examples=150, scenario='ni', sub_dir='ni')\n",
      "\n",
      "Loading data...\n",
      "Loading paths...\n",
      "Loading LUP...\n",
      "Loading labels...\n",
      "preparing CL benchmark...\n",
      "Recovering validation set...\n",
      "----------- batch 0 -------------\n",
      "x shape: (15141, 128, 128, 3), y shape: (15141,)\n",
      "Task Label:  0\n",
      "training ep:  0\n",
      "==>>> it: 0, avg. loss: 0.132176, running train acc: 0.062\n",
      "==>>> it: 100, avg. loss: 0.000279, running train acc: 0.465\n",
      "==>>> it: 200, avg. loss: 0.000077, running train acc: 0.677\n",
      "==>>> it: 300, avg. loss: 0.000030, running train acc: 0.768\n",
      "==>>> it: 400, avg. loss: 0.000013, running train acc: 0.820\n",
      "training ep:  1\n",
      "==>>> it: 0, avg. loss: 0.002098, running train acc: 1.000\n",
      "==>>> it: 100, avg. loss: 0.000013, running train acc: 0.988\n",
      "==>>> it: 200, avg. loss: 0.000004, running train acc: 0.992\n",
      "==>>> it: 300, avg. loss: 0.000002, running train acc: 0.993\n",
      "==>>> it: 400, avg. loss: 0.000002, running train acc: 0.994\n",
      "------------------------------------------\n",
      "Avg. acc: [0.4544241885282348]\n",
      "------------------------------------------\n",
      "----------- batch 1 -------------\n",
      "x shape: (15295, 128, 128, 3), y shape: (15295,)\n",
      "Task Label:  0\n",
      "training ep:  0\n",
      "==>>> it: 0, avg. loss: 0.046588, running train acc: 0.656\n",
      "==>>> it: 100, avg. loss: 0.000036, running train acc: 0.877\n",
      "==>>> it: 200, avg. loss: 0.000007, running train acc: 0.920\n",
      "==>>> it: 300, avg. loss: 0.000004, running train acc: 0.942\n",
      "==>>> it: 400, avg. loss: 0.000007, running train acc: 0.954\n",
      "training ep:  1\n",
      "==>>> it: 0, avg. loss: 0.000886, running train acc: 1.000\n",
      "==>>> it: 100, avg. loss: 0.000004, running train acc: 0.999\n",
      "==>>> it: 200, avg. loss: 0.000000, running train acc: 0.999\n",
      "==>>> it: 300, avg. loss: 0.000001, running train acc: 0.999\n",
      "==>>> it: 400, avg. loss: 0.000001, running train acc: 0.999\n",
      "------------------------------------------\n",
      "Avg. acc: [0.5562472209871053]\n",
      "------------------------------------------\n",
      "----------- batch 2 -------------\n",
      "x shape: (15436, 128, 128, 3), y shape: (15436,)\n",
      "Task Label:  0\n",
      "training ep:  0\n",
      "==>>> it: 0, avg. loss: 0.037738, running train acc: 0.656\n",
      "==>>> it: 100, avg. loss: 0.000070, running train acc: 0.901\n",
      "==>>> it: 200, avg. loss: 0.000017, running train acc: 0.938\n",
      "==>>> it: 300, avg. loss: 0.000006, running train acc: 0.955\n",
      "==>>> it: 400, avg. loss: 0.000001, running train acc: 0.964\n",
      "training ep:  1\n",
      "==>>> it: 0, avg. loss: 0.000304, running train acc: 1.000\n",
      "==>>> it: 100, avg. loss: 0.000023, running train acc: 0.999\n",
      "==>>> it: 200, avg. loss: 0.000001, running train acc: 0.999\n",
      "==>>> it: 300, avg. loss: 0.000000, running train acc: 0.999\n",
      "==>>> it: 400, avg. loss: 0.000000, running train acc: 0.999\n",
      "------------------------------------------\n",
      "Avg. acc: [0.6989773232547799]\n",
      "------------------------------------------\n",
      "----------- batch 3 -------------\n",
      "x shape: (15594, 128, 128, 3), y shape: (15594,)\n",
      "Task Label:  0\n",
      "training ep:  0\n",
      "==>>> it: 0, avg. loss: 0.038512, running train acc: 0.656\n",
      "==>>> it: 100, avg. loss: 0.000065, running train acc: 0.907\n",
      "==>>> it: 200, avg. loss: 0.000008, running train acc: 0.940\n",
      "==>>> it: 300, avg. loss: 0.000002, running train acc: 0.954\n",
      "==>>> it: 400, avg. loss: 0.000004, running train acc: 0.963\n",
      "training ep:  1\n",
      "==>>> it: 0, avg. loss: 0.000663, running train acc: 1.000\n",
      "==>>> it: 100, avg. loss: 0.000004, running train acc: 0.998\n",
      "==>>> it: 200, avg. loss: 0.000007, running train acc: 0.998\n",
      "==>>> it: 300, avg. loss: 0.000000, running train acc: 0.998\n",
      "==>>> it: 400, avg. loss: 0.000001, running train acc: 0.998\n",
      "------------------------------------------\n",
      "Avg. acc: [0.6980880391285016]\n",
      "------------------------------------------\n",
      "----------- batch 4 -------------\n",
      "x shape: (15739, 128, 128, 3), y shape: (15739,)\n",
      "Task Label:  0\n",
      "training ep:  0\n",
      "==>>> it: 0, avg. loss: 0.015739, running train acc: 0.875\n",
      "==>>> it: 100, avg. loss: 0.000086, running train acc: 0.930\n",
      "==>>> it: 200, avg. loss: 0.000005, running train acc: 0.955\n",
      "==>>> it: 300, avg. loss: 0.000002, running train acc: 0.965\n",
      "==>>> it: 400, avg. loss: 0.000001, running train acc: 0.972\n",
      "training ep:  1\n",
      "==>>> it: 0, avg. loss: 0.000525, running train acc: 1.000\n",
      "==>>> it: 100, avg. loss: 0.000001, running train acc: 0.997\n",
      "==>>> it: 200, avg. loss: 0.000005, running train acc: 0.998\n",
      "==>>> it: 300, avg. loss: 0.000000, running train acc: 0.999\n",
      "==>>> it: 400, avg. loss: 0.000000, running train acc: 0.999\n",
      "------------------------------------------\n",
      "Avg. acc: [0.7416629613161405]\n",
      "------------------------------------------\n",
      "----------- batch 5 -------------\n",
      "x shape: (15889, 128, 128, 3), y shape: (15889,)\n",
      "Task Label:  0\n",
      "training ep:  0\n",
      "==>>> it: 0, avg. loss: 0.041155, running train acc: 0.688\n",
      "==>>> it: 100, avg. loss: 0.000030, running train acc: 0.913\n",
      "==>>> it: 200, avg. loss: 0.000003, running train acc: 0.938\n",
      "==>>> it: 300, avg. loss: 0.000004, running train acc: 0.952\n",
      "==>>> it: 400, avg. loss: 0.000007, running train acc: 0.961\n",
      "training ep:  1\n",
      "==>>> it: 0, avg. loss: 0.000221, running train acc: 1.000\n",
      "==>>> it: 100, avg. loss: 0.000021, running train acc: 0.998\n",
      "==>>> it: 200, avg. loss: 0.000000, running train acc: 0.998\n",
      "==>>> it: 300, avg. loss: 0.000001, running train acc: 0.998\n",
      "==>>> it: 400, avg. loss: 0.000002, running train acc: 0.998\n",
      "------------------------------------------\n",
      "Avg. acc: [0.7692307692307693]\n",
      "------------------------------------------\n",
      "----------- batch 6 -------------\n",
      "x shape: (16016, 128, 128, 3), y shape: (16016,)\n",
      "Task Label:  0\n",
      "training ep:  0\n",
      "==>>> it: 0, avg. loss: 0.017798, running train acc: 0.844\n",
      "==>>> it: 100, avg. loss: 0.000007, running train acc: 0.951\n",
      "==>>> it: 200, avg. loss: 0.000003, running train acc: 0.968\n",
      "==>>> it: 300, avg. loss: 0.000001, running train acc: 0.975\n",
      "==>>> it: 400, avg. loss: 0.000000, running train acc: 0.980\n",
      "==>>> it: 500, avg. loss: 0.000000, running train acc: 0.983\n",
      "training ep:  1\n",
      "==>>> it: 0, avg. loss: 0.000983, running train acc: 1.000\n",
      "==>>> it: 100, avg. loss: 0.000002, running train acc: 1.000\n",
      "==>>> it: 200, avg. loss: 0.000001, running train acc: 0.999\n",
      "==>>> it: 300, avg. loss: 0.000004, running train acc: 0.999\n",
      "==>>> it: 400, avg. loss: 0.000000, running train acc: 0.999\n",
      "==>>> it: 500, avg. loss: 0.000001, running train acc: 0.999\n",
      "------------------------------------------\n",
      "Avg. acc: [0.7799021787461093]\n",
      "------------------------------------------\n",
      "----------- batch 7 -------------\n",
      "x shape: (16184, 128, 128, 3), y shape: (16184,)\n",
      "Task Label:  0\n",
      "training ep:  0\n",
      "==>>> it: 0, avg. loss: 0.014168, running train acc: 0.906\n",
      "==>>> it: 100, avg. loss: 0.000076, running train acc: 0.928\n",
      "==>>> it: 200, avg. loss: 0.000018, running train acc: 0.946\n",
      "==>>> it: 300, avg. loss: 0.000000, running train acc: 0.958\n",
      "==>>> it: 400, avg. loss: 0.000001, running train acc: 0.965\n",
      "==>>> it: 500, avg. loss: 0.000004, running train acc: 0.970\n",
      "training ep:  1\n",
      "==>>> it: 0, avg. loss: 0.000101, running train acc: 1.000\n",
      "==>>> it: 100, avg. loss: 0.000038, running train acc: 0.995\n",
      "==>>> it: 200, avg. loss: 0.000001, running train acc: 0.997\n",
      "==>>> it: 300, avg. loss: 0.000001, running train acc: 0.997\n",
      "==>>> it: 400, avg. loss: 0.000000, running train acc: 0.998\n",
      "==>>> it: 500, avg. loss: 0.000000, running train acc: 0.998\n",
      "------------------------------------------\n",
      "Avg. acc: [0.7932414406402846]\n",
      "------------------------------------------\n",
      "Training Time: 29.754185485839844m\n",
      "Final inference on test set...\n",
      "Experiment completed.\n",
      "time for ni: 0:31:35.621979\n",
      "total time: 0:31:35.622267\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "startTime = datetime.now()\n",
    "\n",
    "# scenarios = ['ni', 'multi-task-nc', 'nic']\n",
    "scenarios = ['ni']\n",
    "\n",
    "for s in scenarios:\n",
    "    !python ./naive_baseline_ted.py --scenario=\"{s}\" --sub_dir=\"{s}\" -cls=\"ResNet34\" --replay_examples=150 --epochs=2 -dp=0.5\n",
    "    print('time for {}: {}'.format(s, datetime.now() - startTime))\n",
    "    \n",
    "print('total time: {}'.format(datetime.now() - startTime))\n",
    "\n",
    "# ResNet34 with 150 replay and 0.5 dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(batch_size=32, classifier='ResNet34', cuda=True, device='cuda:0', dropout=0.5, epochs=2, input_size=[3, 128, 128], lr=0.01, n_classes=50, preload_data=True, replay_examples=150, scenario='ni', sub_dir='ni')\n",
      "\n",
      "Loading data...\n",
      "Loading paths...\n",
      "Loading LUP...\n",
      "Loading labels...\n",
      "preparing CL benchmark...\n",
      "Recovering validation set...\n",
      "----------- batch 0 -------------\n",
      "x shape: (15141, 128, 128, 3), y shape: (15141,)\n",
      "Task Label:  0\n",
      "training ep:  0\n",
      "==>>> it: 0, avg. loss: 0.136599, running train acc: 0.000\n",
      "==>>> it: 100, avg. loss: 0.000701, running train acc: 0.216\n",
      "==>>> it: 200, avg. loss: 0.000162, running train acc: 0.426\n",
      "==>>> it: 300, avg. loss: 0.000069, running train acc: 0.558\n",
      "==>>> it: 400, avg. loss: 0.000031, running train acc: 0.641\n",
      "training ep:  1\n",
      "==>>> it: 0, avg. loss: 0.007946, running train acc: 0.969\n",
      "==>>> it: 100, avg. loss: 0.000074, running train acc: 0.962\n",
      "==>>> it: 200, avg. loss: 0.000021, running train acc: 0.966\n",
      "==>>> it: 300, avg. loss: 0.000008, running train acc: 0.973\n",
      "==>>> it: 400, avg. loss: 0.000007, running train acc: 0.978\n",
      "------------------------------------------\n",
      "Avg. acc: [0.47487772343263673]\n",
      "------------------------------------------\n",
      "----------- batch 1 -------------\n",
      "x shape: (15295, 128, 128, 3), y shape: (15295,)\n",
      "Task Label:  0\n",
      "training ep:  0\n",
      "==>>> it: 0, avg. loss: 0.042336, running train acc: 0.625\n",
      "==>>> it: 100, avg. loss: 0.000081, running train acc: 0.855\n",
      "==>>> it: 200, avg. loss: 0.000014, running train acc: 0.902\n",
      "==>>> it: 300, avg. loss: 0.000009, running train acc: 0.925\n",
      "==>>> it: 400, avg. loss: 0.000005, running train acc: 0.939\n",
      "training ep:  1\n",
      "==>>> it: 0, avg. loss: 0.000534, running train acc: 1.000\n",
      "==>>> it: 100, avg. loss: 0.000008, running train acc: 0.994\n",
      "==>>> it: 200, avg. loss: 0.000002, running train acc: 0.995\n",
      "==>>> it: 300, avg. loss: 0.000002, running train acc: 0.996\n",
      "==>>> it: 400, avg. loss: 0.000001, running train acc: 0.996\n",
      "------------------------------------------\n",
      "Avg. acc: [0.5566918630502445]\n",
      "------------------------------------------\n",
      "----------- batch 2 -------------\n",
      "x shape: (15436, 128, 128, 3), y shape: (15436,)\n",
      "Task Label:  0\n",
      "training ep:  0\n",
      "==>>> it: 0, avg. loss: 0.061809, running train acc: 0.594\n",
      "==>>> it: 100, avg. loss: 0.000068, running train acc: 0.877\n",
      "==>>> it: 200, avg. loss: 0.000007, running train acc: 0.914\n",
      "==>>> it: 300, avg. loss: 0.000013, running train acc: 0.935\n",
      "==>>> it: 400, avg. loss: 0.000003, running train acc: 0.948\n",
      "training ep:  1\n",
      "==>>> it: 0, avg. loss: 0.001208, running train acc: 1.000\n",
      "==>>> it: 100, avg. loss: 0.000006, running train acc: 0.994\n",
      "==>>> it: 200, avg. loss: 0.000001, running train acc: 0.995\n",
      "==>>> it: 300, avg. loss: 0.000008, running train acc: 0.996\n",
      "==>>> it: 400, avg. loss: 0.000002, running train acc: 0.997\n",
      "------------------------------------------\n",
      "Avg. acc: [0.7229879946642952]\n",
      "------------------------------------------\n",
      "----------- batch 3 -------------\n",
      "x shape: (15594, 128, 128, 3), y shape: (15594,)\n",
      "Task Label:  0\n",
      "training ep:  0\n",
      "==>>> it: 0, avg. loss: 0.026547, running train acc: 0.812\n",
      "==>>> it: 100, avg. loss: 0.000025, running train acc: 0.894\n",
      "==>>> it: 200, avg. loss: 0.000011, running train acc: 0.923\n",
      "==>>> it: 300, avg. loss: 0.000010, running train acc: 0.939\n",
      "==>>> it: 400, avg. loss: 0.000017, running train acc: 0.950\n",
      "training ep:  1\n",
      "==>>> it: 0, avg. loss: 0.002177, running train acc: 0.969\n",
      "==>>> it: 100, avg. loss: 0.000003, running train acc: 0.994\n",
      "==>>> it: 200, avg. loss: 0.000003, running train acc: 0.993\n",
      "==>>> it: 300, avg. loss: 0.000002, running train acc: 0.995\n",
      "==>>> it: 400, avg. loss: 0.000002, running train acc: 0.996\n",
      "------------------------------------------\n",
      "Avg. acc: [0.7074255224544241]\n",
      "------------------------------------------\n",
      "----------- batch 4 -------------\n",
      "x shape: (15739, 128, 128, 3), y shape: (15739,)\n",
      "Task Label:  0\n",
      "training ep:  0\n",
      "==>>> it: 0, avg. loss: 0.035145, running train acc: 0.781\n",
      "==>>> it: 100, avg. loss: 0.000062, running train acc: 0.925\n",
      "==>>> it: 200, avg. loss: 0.000002, running train acc: 0.946\n",
      "==>>> it: 300, avg. loss: 0.000003, running train acc: 0.958\n",
      "==>>> it: 400, avg. loss: 0.000001, running train acc: 0.966\n",
      "training ep:  1\n",
      "==>>> it: 0, avg. loss: 0.000641, running train acc: 1.000\n",
      "==>>> it: 100, avg. loss: 0.000003, running train acc: 0.995\n",
      "==>>> it: 200, avg. loss: 0.000002, running train acc: 0.996\n",
      "==>>> it: 300, avg. loss: 0.000000, running train acc: 0.996\n",
      "==>>> it: 400, avg. loss: 0.000001, running train acc: 0.997\n",
      "------------------------------------------\n",
      "Avg. acc: [0.7536682970208982]\n",
      "------------------------------------------\n",
      "----------- batch 5 -------------\n",
      "x shape: (15889, 128, 128, 3), y shape: (15889,)\n",
      "Task Label:  0\n",
      "training ep:  0\n",
      "==>>> it: 0, avg. loss: 0.025813, running train acc: 0.750\n",
      "==>>> it: 100, avg. loss: 0.000079, running train acc: 0.886\n",
      "==>>> it: 200, avg. loss: 0.000027, running train acc: 0.919\n",
      "==>>> it: 300, avg. loss: 0.000003, running train acc: 0.937\n",
      "==>>> it: 400, avg. loss: 0.000003, running train acc: 0.947\n",
      "training ep:  1\n",
      "==>>> it: 0, avg. loss: 0.000185, running train acc: 1.000\n",
      "==>>> it: 100, avg. loss: 0.000006, running train acc: 0.995\n",
      "==>>> it: 200, avg. loss: 0.000001, running train acc: 0.995\n",
      "==>>> it: 300, avg. loss: 0.000002, running train acc: 0.996\n",
      "==>>> it: 400, avg. loss: 0.000003, running train acc: 0.996\n",
      "------------------------------------------\n",
      "Avg. acc: [0.7945753668297021]\n",
      "------------------------------------------\n",
      "----------- batch 6 -------------\n",
      "x shape: (16016, 128, 128, 3), y shape: (16016,)\n",
      "Task Label:  0\n",
      "training ep:  0\n",
      "==>>> it: 0, avg. loss: 0.018122, running train acc: 0.844\n",
      "==>>> it: 100, avg. loss: 0.000039, running train acc: 0.935\n",
      "==>>> it: 200, avg. loss: 0.000002, running train acc: 0.957\n",
      "==>>> it: 300, avg. loss: 0.000006, running train acc: 0.967\n",
      "==>>> it: 400, avg. loss: 0.000002, running train acc: 0.973\n",
      "==>>> it: 500, avg. loss: 0.000000, running train acc: 0.977\n",
      "training ep:  1\n",
      "==>>> it: 0, avg. loss: 0.000205, running train acc: 1.000\n",
      "==>>> it: 100, avg. loss: 0.000002, running train acc: 0.997\n",
      "==>>> it: 200, avg. loss: 0.000001, running train acc: 0.998\n",
      "==>>> it: 300, avg. loss: 0.000001, running train acc: 0.998\n",
      "==>>> it: 400, avg. loss: 0.000001, running train acc: 0.998\n",
      "==>>> it: 500, avg. loss: 0.000000, running train acc: 0.998\n",
      "------------------------------------------\n",
      "Avg. acc: [0.791907514450867]\n",
      "------------------------------------------\n",
      "----------- batch 7 -------------\n",
      "x shape: (16184, 128, 128, 3), y shape: (16184,)\n",
      "Task Label:  0\n",
      "training ep:  0\n",
      "==>>> it: 0, avg. loss: 0.014314, running train acc: 0.844\n",
      "==>>> it: 100, avg. loss: 0.000053, running train acc: 0.921\n",
      "==>>> it: 200, avg. loss: 0.000023, running train acc: 0.935\n",
      "==>>> it: 300, avg. loss: 0.000018, running train acc: 0.945\n",
      "==>>> it: 400, avg. loss: 0.000010, running train acc: 0.954\n",
      "==>>> it: 500, avg. loss: 0.000001, running train acc: 0.959\n",
      "training ep:  1\n",
      "==>>> it: 0, avg. loss: 0.001194, running train acc: 1.000\n",
      "==>>> it: 100, avg. loss: 0.000001, running train acc: 0.992\n",
      "==>>> it: 200, avg. loss: 0.000009, running train acc: 0.991\n",
      "==>>> it: 300, avg. loss: 0.000003, running train acc: 0.993\n",
      "==>>> it: 400, avg. loss: 0.000002, running train acc: 0.993\n",
      "==>>> it: 500, avg. loss: 0.000000, running train acc: 0.994\n",
      "------------------------------------------\n",
      "Avg. acc: [0.8199199644286349]\n",
      "------------------------------------------\n",
      "Training Time: 29.79192223548889m\n",
      "Final inference on test set...\n",
      "Experiment completed.\n",
      "time for ni: 0:31:37.308031\n",
      "total time: 0:31:37.308354\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "startTime = datetime.now()\n",
    "\n",
    "# scenarios = ['ni', 'multi-task-nc', 'nic']\n",
    "scenarios = ['ni']\n",
    "\n",
    "for s in scenarios:\n",
    "    !python ./naive_baseline_ted.py --scenario=\"{s}\" --sub_dir=\"{s}\" -cls=\"ResNet34\" --replay_examples=150 --epochs=2 -dp=0.5\n",
    "    print('time for {}: {}'.format(s, datetime.now() - startTime))\n",
    "    \n",
    "print('total time: {}'.format(datetime.now() - startTime))\n",
    "\n",
    "# ResNet34 with 150 replay and 0.5 dropout, DO -> 512 -> DO -> 128 -> 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(batch_size=32, classifier='ResNet34', cuda=True, device='cuda:0', dropout=0.5, epochs=2, input_size=[3, 128, 128], lr=0.01, n_classes=50, preload_data=True, replay_examples=150, scenario='ni', sub_dir='ni')\n",
      "\n",
      "Loading data...\n",
      "Loading paths...\n",
      "Loading LUP...\n",
      "Loading labels...\n",
      "preparing CL benchmark...\n",
      "Recovering validation set...\n",
      "----------- batch 0 -------------\n",
      "x shape: (15141, 128, 128, 3), y shape: (15141,)\n",
      "Task Label:  0\n",
      "training ep:  0\n",
      "==>>> it: 0, avg. loss: 0.130126, running train acc: 0.031\n",
      "==>>> it: 100, avg. loss: 0.000380, running train acc: 0.484\n",
      "==>>> it: 200, avg. loss: 0.000333, running train acc: 0.559\n",
      "==>>> it: 300, avg. loss: 0.000292, running train acc: 0.516\n",
      "==>>> it: 400, avg. loss: 0.000221, running train acc: 0.465\n",
      "training ep:  1\n",
      "==>>> it: 0, avg. loss: 0.093698, running train acc: 0.219\n",
      "==>>> it: 100, avg. loss: 0.000889, running train acc: 0.222\n",
      "==>>> it: 200, avg. loss: 0.000448, running train acc: 0.212\n",
      "==>>> it: 300, avg. loss: 0.000330, running train acc: 0.193\n",
      "==>>> it: 400, avg. loss: 0.000235, running train acc: 0.179\n",
      "------------------------------------------\n",
      "Avg. acc: [0.039573143619386394]\n",
      "------------------------------------------\n",
      "----------- batch 1 -------------\n",
      "x shape: (15295, 128, 128, 3), y shape: (15295,)\n",
      "Task Label:  0\n",
      "training ep:  0\n",
      "==>>> it: 0, avg. loss: 0.106560, running train acc: 0.094\n",
      "==>>> it: 100, avg. loss: 0.001021, running train acc: 0.074\n",
      "==>>> it: 200, avg. loss: 0.000535, running train acc: 0.071\n",
      "==>>> it: 300, avg. loss: 0.000350, running train acc: 0.068\n",
      "==>>> it: 400, avg. loss: 0.000261, running train acc: 0.063\n",
      "^C\n",
      "Traceback (most recent call last):\n",
      "  File \"./naive_baseline_ted.py\", line 218, in <module>\n",
      "    main(args)\n",
      "  File \"./naive_baseline_ted.py\", line 123, in main\n",
      "    args.epochs, preproc=preprocess_imgs\n",
      "  File \"/data/home/ted/notebooks/njit/cvpr_clvision_challenge/utils/train_test.py\", line 104, in train_net\n",
      "    acc = correct_cnt.item() / \\\n",
      "KeyboardInterrupt\n",
      "time for ni: 0:05:38.638949\n",
      "total time: 0:05:38.639270\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "startTime = datetime.now()\n",
    "\n",
    "# scenarios = ['ni', 'multi-task-nc', 'nic']\n",
    "scenarios = ['ni']\n",
    "\n",
    "for s in scenarios:\n",
    "    !python ./naive_baseline_ted.py --scenario=\"{s}\" --sub_dir=\"{s}\" -cls=\"ResNet34\" --replay_examples=150 --epochs=2 -dp=0.5\n",
    "    print('time for {}: {}'.format(s, datetime.now() - startTime))\n",
    "    \n",
    "print('total time: {}'.format(datetime.now() - startTime))\n",
    "\n",
    "# ResNet34 with 150 replay and 0.5 dropout, momentum=0.9, DO -> 512 -> DO -> 128 -> 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(batch_size=32, classifier='ResNet34', cuda=True, device='cuda:0', dropout=0.5, epochs=2, input_size=[3, 128, 128], lr=0.01, n_classes=50, preload_data=True, replay_examples=150, scenario='ni', sub_dir='ni')\n",
      "\n",
      "Loading data...\n",
      "Loading paths...\n",
      "Loading LUP...\n",
      "Loading labels...\n",
      "preparing CL benchmark...\n",
      "Recovering validation set...\n",
      "----------- batch 0 -------------\n",
      "x shape: (15141, 128, 128, 3), y shape: (15141,)\n",
      "Task Label:  0\n",
      "training ep:  0\n",
      "==>>> it: 0, avg. loss: 0.135652, running train acc: 0.000\n",
      "==>>> it: 100, avg. loss: 0.000742, running train acc: 0.215\n",
      "==>>> it: 200, avg. loss: 0.000232, running train acc: 0.415\n",
      "==>>> it: 300, avg. loss: 0.000120, running train acc: 0.543\n",
      "==>>> it: 400, avg. loss: 0.000068, running train acc: 0.628\n",
      "training ep:  1\n",
      "==>>> it: 0, avg. loss: 0.023361, running train acc: 0.969\n",
      "==>>> it: 100, avg. loss: 0.000219, running train acc: 0.944\n",
      "==>>> it: 200, avg. loss: 0.000091, running train acc: 0.954\n",
      "==>>> it: 300, avg. loss: 0.000066, running train acc: 0.963\n",
      "==>>> it: 400, avg. loss: 0.000063, running train acc: 0.968\n",
      "------------------------------------------\n",
      "Avg. acc: [0.5326811916407292]\n",
      "------------------------------------------\n",
      "----------- batch 1 -------------\n",
      "x shape: (15295, 128, 128, 3), y shape: (15295,)\n",
      "Task Label:  0\n",
      "training ep:  0\n",
      "==>>> it: 0, avg. loss: 0.059332, running train acc: 0.562\n",
      "==>>> it: 100, avg. loss: 0.000269, running train acc: 0.896\n",
      "==>>> it: 200, avg. loss: 0.000125, running train acc: 0.928\n",
      "==>>> it: 300, avg. loss: 0.000099, running train acc: 0.944\n",
      "==>>> it: 400, avg. loss: 0.000064, running train acc: 0.954\n",
      "training ep:  1\n",
      "==>>> it: 0, avg. loss: 0.030227, running train acc: 1.000\n",
      "==>>> it: 100, avg. loss: 0.000339, running train acc: 0.993\n",
      "==>>> it: 200, avg. loss: 0.000139, running train acc: 0.991\n",
      "==>>> it: 300, avg. loss: 0.000119, running train acc: 0.989\n",
      "==>>> it: 400, avg. loss: 0.000074, running train acc: 0.987\n",
      "------------------------------------------\n",
      "Avg. acc: [0.28457092040907067]\n",
      "------------------------------------------\n",
      "----------- batch 2 -------------\n",
      "x shape: (15436, 128, 128, 3), y shape: (15436,)\n",
      "Task Label:  0\n",
      "training ep:  0\n",
      "==>>> it: 0, avg. loss: 0.065260, running train acc: 0.594\n",
      "==>>> it: 100, avg. loss: 0.000419, running train acc: 0.747\n",
      "==>>> it: 200, avg. loss: 0.000220, running train acc: 0.823\n",
      "==>>> it: 300, avg. loss: 0.000136, running train acc: 0.850\n",
      "==>>> it: 400, avg. loss: 0.000100, running train acc: 0.859\n",
      "training ep:  1\n",
      "==>>> it: 0, avg. loss: 0.043250, running train acc: 0.938\n",
      "==>>> it: 100, avg. loss: 0.000419, running train acc: 0.906\n",
      "==>>> it: 200, avg. loss: 0.000221, running train acc: 0.912\n",
      "==>>> it: 300, avg. loss: 0.000152, running train acc: 0.908\n",
      "==>>> it: 400, avg. loss: 0.000141, running train acc: 0.880\n",
      "------------------------------------------\n",
      "Avg. acc: [0.21076033792796797]\n",
      "------------------------------------------\n",
      "----------- batch 3 -------------\n",
      "x shape: (15594, 128, 128, 3), y shape: (15594,)\n",
      "Task Label:  0\n",
      "training ep:  0\n",
      "==>>> it: 0, avg. loss: 0.075957, running train acc: 0.500\n",
      "==>>> it: 100, avg. loss: 0.000611, running train acc: 0.535\n",
      "==>>> it: 200, avg. loss: 0.000302, running train acc: 0.631\n",
      "==>>> it: 300, avg. loss: 0.000190, running train acc: 0.667\n",
      "==>>> it: 400, avg. loss: 0.000134, running train acc: 0.693\n",
      "training ep:  1\n",
      "==>>> it: 0, avg. loss: 0.055741, running train acc: 0.938\n",
      "==>>> it: 100, avg. loss: 0.000547, running train acc: 0.809\n",
      "==>>> it: 200, avg. loss: 0.000276, running train acc: 0.789\n",
      "==>>> it: 300, avg. loss: 0.000170, running train acc: 0.770\n",
      "==>>> it: 400, avg. loss: 0.000136, running train acc: 0.775\n",
      "------------------------------------------\n",
      "Avg. acc: [0.14228546020453534]\n",
      "------------------------------------------\n",
      "----------- batch 4 -------------\n",
      "x shape: (15739, 128, 128, 3), y shape: (15739,)\n",
      "Task Label:  0\n",
      "training ep:  0\n",
      "==>>> it: 0, avg. loss: 0.074050, running train acc: 0.438\n",
      "==>>> it: 100, avg. loss: 0.000692, running train acc: 0.551\n",
      "==>>> it: 200, avg. loss: 0.000295, running train acc: 0.622\n",
      "==>>> it: 300, avg. loss: 0.000197, running train acc: 0.645\n",
      "==>>> it: 400, avg. loss: 0.000142, running train acc: 0.668\n",
      "training ep:  1\n",
      "==>>> it: 0, avg. loss: 0.054130, running train acc: 0.812\n",
      "==>>> it: 100, avg. loss: 0.000582, running train acc: 0.754\n",
      "==>>> it: 200, avg. loss: 0.000281, running train acc: 0.743\n",
      "==>>> it: 300, avg. loss: 0.000179, running train acc: 0.728\n",
      "^C\n",
      "Traceback (most recent call last):\n",
      "  File \"./naive_baseline_ted.py\", line 218, in <module>\n",
      "    main(args)\n",
      "  File \"./naive_baseline_ted.py\", line 123, in main\n",
      "    args.epochs, preproc=preprocess_imgs\n",
      "  File \"/data/home/ted/notebooks/njit/cvpr_clvision_challenge/utils/train_test.py\", line 104, in train_net\n",
      "    acc = correct_cnt.item() / \\\n",
      "KeyboardInterrupt\n",
      "time for ni: 0:18:08.933029\n",
      "total time: 0:18:08.933347\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "startTime = datetime.now()\n",
    "\n",
    "# scenarios = ['ni', 'multi-task-nc', 'nic']\n",
    "scenarios = ['ni']\n",
    "\n",
    "for s in scenarios:\n",
    "    !python ./naive_baseline_ted.py --scenario=\"{s}\" --sub_dir=\"{s}\" -cls=\"ResNet34\" --replay_examples=150 --epochs=2 -dp=0.5\n",
    "    print('time for {}: {}'.format(s, datetime.now() - startTime))\n",
    "    \n",
    "print('total time: {}'.format(datetime.now() - startTime))\n",
    "\n",
    "# ResNet34 with 150 replay and 0.5 dropout, weight_decay=0.1, DO -> 512 -> DO -> 128 -> 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(batch_size=32, classifier='ResNet34', cuda=True, device='cuda:0', dropout=0.5, epochs=2, input_size=[3, 128, 128], lr=0.01, n_classes=50, preload_data=True, replay_examples=150, scenario='ni', sub_dir='ni')\n",
      "\n",
      "Loading data...\n",
      "Loading paths...\n",
      "Loading LUP...\n",
      "Loading labels...\n",
      "preparing CL benchmark...\n",
      "Recovering validation set...\n",
      "----------- batch 0 -------------\n",
      "x shape: (15141, 128, 128, 3), y shape: (15141,)\n",
      "Task Label:  0\n",
      "training ep:  0\n",
      "==>>> it: 0, avg. loss: 0.141228, running train acc: 0.000\n",
      "==>>> it: 100, avg. loss: 0.001286, running train acc: 0.021\n",
      "==>>> it: 200, avg. loss: 0.000521, running train acc: 0.037\n",
      "==>>> it: 300, avg. loss: 0.000338, running train acc: 0.055\n",
      "==>>> it: 400, avg. loss: 0.000193, running train acc: 0.077\n",
      "training ep:  1\n",
      "==>>> it: 0, avg. loss: 0.075446, running train acc: 0.281\n",
      "==>>> it: 100, avg. loss: 0.000779, running train acc: 0.248\n",
      "==>>> it: 200, avg. loss: 0.000289, running train acc: 0.290\n",
      "==>>> it: 300, avg. loss: 0.000230, running train acc: 0.318\n",
      "==>>> it: 400, avg. loss: 0.000105, running train acc: 0.337\n",
      "------------------------------------------\n",
      "Avg. acc: [0.0493552690084482]\n",
      "------------------------------------------\n",
      "----------- batch 1 -------------\n",
      "x shape: (15295, 128, 128, 3), y shape: (15295,)\n",
      "Task Label:  0\n",
      "training ep:  0\n",
      "==>>> it: 0, avg. loss: 0.156102, running train acc: 0.031\n",
      "==>>> it: 100, avg. loss: 0.000893, running train acc: 0.134\n",
      "==>>> it: 200, avg. loss: 0.000461, running train acc: 0.202\n",
      "==>>> it: 300, avg. loss: 0.000191, running train acc: 0.264\n",
      "==>>> it: 400, avg. loss: 0.000163, running train acc: 0.316\n",
      "training ep:  1\n",
      "==>>> it: 0, avg. loss: 0.050159, running train acc: 0.625\n",
      "==>>> it: 100, avg. loss: 0.000336, running train acc: 0.580\n",
      "==>>> it: 200, avg. loss: 0.000251, running train acc: 0.595\n",
      "==>>> it: 300, avg. loss: 0.000099, running train acc: 0.622\n",
      "==>>> it: 400, avg. loss: 0.000090, running train acc: 0.637\n",
      "------------------------------------------\n",
      "Avg. acc: [0.05246776345042241]\n",
      "------------------------------------------\n",
      "----------- batch 2 -------------\n",
      "x shape: (15436, 128, 128, 3), y shape: (15436,)\n",
      "Task Label:  0\n",
      "training ep:  0\n",
      "==>>> it: 0, avg. loss: 0.296941, running train acc: 0.094\n",
      "==>>> it: 100, avg. loss: 0.000678, running train acc: 0.174\n",
      "==>>> it: 200, avg. loss: 0.000261, running train acc: 0.279\n",
      "==>>> it: 300, avg. loss: 0.000139, running train acc: 0.340\n",
      "==>>> it: 400, avg. loss: 0.000095, running train acc: 0.393\n",
      "training ep:  1\n",
      "==>>> it: 0, avg. loss: 0.047276, running train acc: 0.500\n",
      "==>>> it: 100, avg. loss: 0.000420, running train acc: 0.656\n",
      "==>>> it: 200, avg. loss: 0.000169, running train acc: 0.685\n",
      "==>>> it: 300, avg. loss: 0.000096, running train acc: 0.694\n",
      "==>>> it: 400, avg. loss: 0.000044, running train acc: 0.709\n",
      "------------------------------------------\n",
      "Avg. acc: [0.14361938639395286]\n",
      "------------------------------------------\n",
      "----------- batch 3 -------------\n",
      "x shape: (15594, 128, 128, 3), y shape: (15594,)\n",
      "Task Label:  0\n",
      "training ep:  0\n",
      "==>>> it: 0, avg. loss: 0.137723, running train acc: 0.219\n",
      "==>>> it: 100, avg. loss: 0.000531, running train acc: 0.329\n",
      "==>>> it: 200, avg. loss: 0.000183, running train acc: 0.421\n",
      "==>>> it: 300, avg. loss: 0.000147, running train acc: 0.480\n",
      "==>>> it: 400, avg. loss: 0.000091, running train acc: 0.516\n",
      "training ep:  1\n",
      "==>>> it: 0, avg. loss: 0.026824, running train acc: 0.688\n",
      "==>>> it: 100, avg. loss: 0.000282, running train acc: 0.699\n",
      "==>>> it: 200, avg. loss: 0.000136, running train acc: 0.704\n",
      "==>>> it: 300, avg. loss: 0.000068, running train acc: 0.721\n",
      "==>>> it: 400, avg. loss: 0.000038, running train acc: 0.733\n",
      "------------------------------------------\n",
      "Avg. acc: [0.10626945309026234]\n",
      "------------------------------------------\n",
      "----------- batch 4 -------------\n",
      "x shape: (15739, 128, 128, 3), y shape: (15739,)\n",
      "Task Label:  0\n",
      "training ep:  0\n",
      "==>>> it: 0, avg. loss: 0.106913, running train acc: 0.281\n",
      "==>>> it: 100, avg. loss: 0.000448, running train acc: 0.431\n",
      "==>>> it: 200, avg. loss: 0.000227, running train acc: 0.502\n",
      "==>>> it: 300, avg. loss: 0.000142, running train acc: 0.547\n",
      "==>>> it: 400, avg. loss: 0.000089, running train acc: 0.575\n",
      "training ep:  1\n",
      "==>>> it: 0, avg. loss: 0.012295, running train acc: 0.938\n",
      "==>>> it: 100, avg. loss: 0.000219, running train acc: 0.694\n",
      "==>>> it: 200, avg. loss: 0.000117, running train acc: 0.723\n",
      "==>>> it: 300, avg. loss: 0.000062, running train acc: 0.740\n",
      "==>>> it: 400, avg. loss: 0.000044, running train acc: 0.754\n",
      "------------------------------------------\n",
      "Avg. acc: [0.17163183637172078]\n",
      "------------------------------------------\n",
      "----------- batch 5 -------------\n",
      "x shape: (15889, 128, 128, 3), y shape: (15889,)\n",
      "Task Label:  0\n",
      "training ep:  0\n",
      "==>>> it: 0, avg. loss: 0.118727, running train acc: 0.219\n",
      "==>>> it: 100, avg. loss: 0.000518, running train acc: 0.377\n",
      "==>>> it: 200, avg. loss: 0.000229, running train acc: 0.461\n",
      "==>>> it: 300, avg. loss: 0.000131, running train acc: 0.508\n",
      "==>>> it: 400, avg. loss: 0.000118, running train acc: 0.547\n",
      "training ep:  1\n",
      "==>>> it: 0, avg. loss: 0.026855, running train acc: 0.688\n",
      "==>>> it: 100, avg. loss: 0.000262, running train acc: 0.741\n",
      "==>>> it: 200, avg. loss: 0.000079, running train acc: 0.754\n",
      "==>>> it: 300, avg. loss: 0.000093, running train acc: 0.762\n",
      "==>>> it: 400, avg. loss: 0.000061, running train acc: 0.770\n",
      "------------------------------------------\n",
      "Avg. acc: [0.15206758559359715]\n",
      "------------------------------------------\n",
      "----------- batch 6 -------------\n",
      "x shape: (16016, 128, 128, 3), y shape: (16016,)\n",
      "Task Label:  0\n",
      "training ep:  0\n",
      "==>>> it: 0, avg. loss: 0.118275, running train acc: 0.375\n",
      "==>>> it: 100, avg. loss: 0.000218, running train acc: 0.496\n",
      "==>>> it: 200, avg. loss: 0.000161, running train acc: 0.598\n",
      "==>>> it: 300, avg. loss: 0.000041, running train acc: 0.650\n",
      "==>>> it: 400, avg. loss: 0.000052, running train acc: 0.683\n",
      "==>>> it: 500, avg. loss: 0.000039, running train acc: 0.708\n",
      "training ep:  1\n",
      "==>>> it: 0, avg. loss: 0.018055, running train acc: 0.812\n",
      "==>>> it: 100, avg. loss: 0.000166, running train acc: 0.838\n",
      "==>>> it: 200, avg. loss: 0.000095, running train acc: 0.843\n",
      "==>>> it: 300, avg. loss: 0.000024, running train acc: 0.851\n",
      "==>>> it: 400, avg. loss: 0.000049, running train acc: 0.858\n",
      "==>>> it: 500, avg. loss: 0.000015, running train acc: 0.862\n",
      "------------------------------------------\n",
      "Avg. acc: [0.16540684748777235]\n",
      "------------------------------------------\n",
      "----------- batch 7 -------------\n",
      "x shape: (16184, 128, 128, 3), y shape: (16184,)\n",
      "Task Label:  0\n",
      "training ep:  0\n",
      "==>>> it: 0, avg. loss: 0.098258, running train acc: 0.281\n",
      "==>>> it: 100, avg. loss: 0.000378, running train acc: 0.472\n",
      "==>>> it: 200, avg. loss: 0.000153, running train acc: 0.539\n",
      "==>>> it: 300, avg. loss: 0.000124, running train acc: 0.578\n",
      "==>>> it: 400, avg. loss: 0.000043, running train acc: 0.610\n",
      "==>>> it: 500, avg. loss: 0.000073, running train acc: 0.631\n",
      "training ep:  1\n",
      "==>>> it: 0, avg. loss: 0.017163, running train acc: 0.812\n",
      "==>>> it: 100, avg. loss: 0.000218, running train acc: 0.761\n",
      "==>>> it: 200, avg. loss: 0.000377, running train acc: 0.654\n",
      "==>>> it: 300, avg. loss: 0.000118, running train acc: 0.632\n",
      "==>>> it: 400, avg. loss: 0.000065, running train acc: 0.655\n",
      "==>>> it: 500, avg. loss: 0.000060, running train acc: 0.673\n",
      "------------------------------------------\n",
      "Avg. acc: [0.1956425077812361]\n",
      "------------------------------------------\n",
      "Training Time: 31.043943226337433m\n",
      "Final inference on test set...\n",
      "Experiment completed.\n",
      "time for ni: 0:32:53.496849\n",
      "total time: 0:32:53.497123\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "startTime = datetime.now()\n",
    "\n",
    "# scenarios = ['ni', 'multi-task-nc', 'nic']\n",
    "scenarios = ['ni']\n",
    "\n",
    "for s in scenarios:\n",
    "    !python ./naive_baseline_ted.py --scenario=\"{s}\" --sub_dir=\"{s}\" -cls=\"ResNet34\" --replay_examples=150 --epochs=2 -dp=0.5\n",
    "    print('time for {}: {}'.format(s, datetime.now() - startTime))\n",
    "    \n",
    "print('total time: {}'.format(datetime.now() - startTime))\n",
    "\n",
    "# ResNet34 with 150 replay and 0.5 dropout, weight_decay=0.1, DO -> 512 -> DO -> 128 -> 10, ADAM optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(batch_size=32, classifier='ResNet34', cuda=True, device='cuda:0', dropout=0.5, epochs=2, input_size=[3, 128, 128], lr=0.005, n_classes=50, preload_data=True, replay_examples=150, scenario='ni', sub_dir='ni')\n",
      "\n",
      "Loading data...\n",
      "Loading paths...\n",
      "Loading LUP...\n",
      "Loading labels...\n",
      "preparing CL benchmark...\n",
      "Recovering validation set...\n",
      "----------- batch 0 -------------\n",
      "x shape: (15141, 128, 128, 3), y shape: (15141,)\n",
      "Task Label:  0\n",
      "training ep:  0\n",
      "==>>> it: 0, avg. loss: 0.137971, running train acc: 0.000\n",
      "==>>> it: 100, avg. loss: 0.001081, running train acc: 0.096\n",
      "==>>> it: 200, avg. loss: 0.000368, running train acc: 0.227\n",
      "==>>> it: 300, avg. loss: 0.000165, running train acc: 0.341\n",
      "==>>> it: 400, avg. loss: 0.000100, running train acc: 0.438\n",
      "training ep:  1\n",
      "==>>> it: 0, avg. loss: 0.019243, running train acc: 0.938\n",
      "==>>> it: 100, avg. loss: 0.000169, running train acc: 0.864\n",
      "==>>> it: 200, avg. loss: 0.000054, running train acc: 0.885\n",
      "==>>> it: 300, avg. loss: 0.000043, running train acc: 0.896\n",
      "==>>> it: 400, avg. loss: 0.000037, running train acc: 0.910\n",
      "------------------------------------------\n",
      "Avg. acc: [0.4753223654957759]\n",
      "------------------------------------------\n",
      "----------- batch 1 -------------\n",
      "x shape: (15295, 128, 128, 3), y shape: (15295,)\n",
      "Task Label:  0\n",
      "training ep:  0\n",
      "==>>> it: 0, avg. loss: 0.050774, running train acc: 0.562\n",
      "==>>> it: 100, avg. loss: 0.000135, running train acc: 0.774\n",
      "==>>> it: 200, avg. loss: 0.000067, running train acc: 0.835\n",
      "==>>> it: 300, avg. loss: 0.000019, running train acc: 0.865\n",
      "==>>> it: 400, avg. loss: 0.000022, running train acc: 0.887\n",
      "training ep:  1\n",
      "==>>> it: 0, avg. loss: 0.005807, running train acc: 0.969\n",
      "==>>> it: 100, avg. loss: 0.000019, running train acc: 0.981\n",
      "==>>> it: 200, avg. loss: 0.000022, running train acc: 0.982\n",
      "==>>> it: 300, avg. loss: 0.000008, running train acc: 0.983\n",
      "==>>> it: 400, avg. loss: 0.000004, running train acc: 0.985\n",
      "------------------------------------------\n",
      "Avg. acc: [0.5762561138283682]\n",
      "------------------------------------------\n",
      "----------- batch 2 -------------\n",
      "x shape: (15436, 128, 128, 3), y shape: (15436,)\n",
      "Task Label:  0\n",
      "training ep:  0\n",
      "==>>> it: 0, avg. loss: 0.040511, running train acc: 0.625\n",
      "==>>> it: 100, avg. loss: 0.000077, running train acc: 0.835\n",
      "==>>> it: 200, avg. loss: 0.000021, running train acc: 0.881\n",
      "==>>> it: 300, avg. loss: 0.000012, running train acc: 0.906\n",
      "==>>> it: 400, avg. loss: 0.000008, running train acc: 0.921\n",
      "training ep:  1\n",
      "==>>> it: 0, avg. loss: 0.001318, running train acc: 1.000\n",
      "==>>> it: 100, avg. loss: 0.000011, running train acc: 0.985\n",
      "==>>> it: 200, avg. loss: 0.000004, running train acc: 0.988\n",
      "==>>> it: 300, avg. loss: 0.000005, running train acc: 0.991\n",
      "==>>> it: 400, avg. loss: 0.000001, running train acc: 0.992\n",
      "------------------------------------------\n",
      "Avg. acc: [0.7083148065807026]\n",
      "------------------------------------------\n",
      "----------- batch 3 -------------\n",
      "x shape: (15594, 128, 128, 3), y shape: (15594,)\n",
      "Task Label:  0\n",
      "training ep:  0\n",
      "==>>> it: 0, avg. loss: 0.031584, running train acc: 0.781\n",
      "==>>> it: 100, avg. loss: 0.000062, running train acc: 0.879\n",
      "==>>> it: 200, avg. loss: 0.000010, running train acc: 0.908\n",
      "==>>> it: 300, avg. loss: 0.000010, running train acc: 0.924\n",
      "==>>> it: 400, avg. loss: 0.000010, running train acc: 0.935\n",
      "training ep:  1\n",
      "==>>> it: 0, avg. loss: 0.001205, running train acc: 1.000\n",
      "==>>> it: 100, avg. loss: 0.000011, running train acc: 0.994\n",
      "==>>> it: 200, avg. loss: 0.000011, running train acc: 0.993\n",
      "==>>> it: 300, avg. loss: 0.000001, running train acc: 0.993\n",
      "==>>> it: 400, avg. loss: 0.000002, running train acc: 0.994\n",
      "------------------------------------------\n",
      "Avg. acc: [0.6820809248554913]\n",
      "------------------------------------------\n",
      "----------- batch 4 -------------\n",
      "x shape: (15739, 128, 128, 3), y shape: (15739,)\n",
      "Task Label:  0\n",
      "training ep:  0\n",
      "==>>> it: 0, avg. loss: 0.018242, running train acc: 0.875\n",
      "==>>> it: 100, avg. loss: 0.000040, running train acc: 0.909\n",
      "==>>> it: 200, avg. loss: 0.000046, running train acc: 0.933\n",
      "==>>> it: 300, avg. loss: 0.000008, running train acc: 0.945\n",
      "==>>> it: 400, avg. loss: 0.000007, running train acc: 0.953\n",
      "training ep:  1\n",
      "==>>> it: 0, avg. loss: 0.001072, running train acc: 1.000\n",
      "==>>> it: 100, avg. loss: 0.000011, running train acc: 0.995\n",
      "==>>> it: 200, avg. loss: 0.000009, running train acc: 0.995\n",
      "==>>> it: 300, avg. loss: 0.000001, running train acc: 0.996\n",
      "==>>> it: 400, avg. loss: 0.000001, running train acc: 0.996\n",
      "------------------------------------------\n",
      "Avg. acc: [0.7683414851044909]\n",
      "------------------------------------------\n",
      "----------- batch 5 -------------\n",
      "x shape: (15889, 128, 128, 3), y shape: (15889,)\n",
      "Task Label:  0\n",
      "training ep:  0\n",
      "==>>> it: 0, avg. loss: 0.040833, running train acc: 0.656\n",
      "==>>> it: 100, avg. loss: 0.000082, running train acc: 0.874\n",
      "==>>> it: 200, avg. loss: 0.000019, running train acc: 0.906\n",
      "==>>> it: 300, avg. loss: 0.000004, running train acc: 0.923\n",
      "==>>> it: 400, avg. loss: 0.000010, running train acc: 0.935\n",
      "training ep:  1\n",
      "==>>> it: 0, avg. loss: 0.001536, running train acc: 0.969\n",
      "==>>> it: 100, avg. loss: 0.000022, running train acc: 0.991\n",
      "==>>> it: 200, avg. loss: 0.000002, running train acc: 0.993\n",
      "==>>> it: 300, avg. loss: 0.000002, running train acc: 0.994\n",
      "==>>> it: 400, avg. loss: 0.000002, running train acc: 0.994\n",
      "------------------------------------------\n",
      "Avg. acc: [0.7781236104935527]\n",
      "------------------------------------------\n",
      "----------- batch 6 -------------\n",
      "x shape: (16016, 128, 128, 3), y shape: (16016,)\n",
      "Task Label:  0\n",
      "training ep:  0\n",
      "==>>> it: 0, avg. loss: 0.040536, running train acc: 0.719\n",
      "==>>> it: 100, avg. loss: 0.000052, running train acc: 0.929\n",
      "==>>> it: 200, avg. loss: 0.000036, running train acc: 0.951\n",
      "==>>> it: 300, avg. loss: 0.000013, running train acc: 0.962\n",
      "==>>> it: 400, avg. loss: 0.000002, running train acc: 0.968\n",
      "==>>> it: 500, avg. loss: 0.000001, running train acc: 0.973\n",
      "training ep:  1\n",
      "==>>> it: 0, avg. loss: 0.002291, running train acc: 0.969\n",
      "==>>> it: 100, avg. loss: 0.000025, running train acc: 0.996\n",
      "==>>> it: 200, avg. loss: 0.000001, running train acc: 0.997\n",
      "==>>> it: 300, avg. loss: 0.000004, running train acc: 0.997\n",
      "==>>> it: 400, avg. loss: 0.000001, running train acc: 0.997\n",
      "==>>> it: 500, avg. loss: 0.000001, running train acc: 0.998\n",
      "------------------------------------------\n",
      "Avg. acc: [0.7825700311249444]\n",
      "------------------------------------------\n",
      "----------- batch 7 -------------\n",
      "x shape: (16184, 128, 128, 3), y shape: (16184,)\n",
      "Task Label:  0\n",
      "training ep:  0\n",
      "==>>> it: 0, avg. loss: 0.033720, running train acc: 0.781\n",
      "==>>> it: 100, avg. loss: 0.000101, running train acc: 0.910\n",
      "==>>> it: 200, avg. loss: 0.000026, running train acc: 0.934\n",
      "==>>> it: 300, avg. loss: 0.000003, running train acc: 0.945\n",
      "==>>> it: 400, avg. loss: 0.000009, running train acc: 0.953\n",
      "==>>> it: 500, avg. loss: 0.000011, running train acc: 0.958\n",
      "training ep:  1\n",
      "==>>> it: 0, avg. loss: 0.002451, running train acc: 0.969\n",
      "==>>> it: 100, avg. loss: 0.000003, running train acc: 0.993\n",
      "==>>> it: 200, avg. loss: 0.000011, running train acc: 0.992\n",
      "==>>> it: 300, avg. loss: 0.000001, running train acc: 0.993\n",
      "==>>> it: 400, avg. loss: 0.000005, running train acc: 0.993\n",
      "==>>> it: 500, avg. loss: 0.000002, running train acc: 0.993\n",
      "------------------------------------------\n",
      "Avg. acc: [0.7914628723877278]\n",
      "------------------------------------------\n",
      "Training Time: 30.11689031124115m\n",
      "Final inference on test set...\n",
      "Experiment completed.\n",
      "time for ni: 0:31:56.935910\n",
      "total time: 0:31:56.936191\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "startTime = datetime.now()\n",
    "\n",
    "# scenarios = ['ni', 'multi-task-nc', 'nic']\n",
    "scenarios = ['ni']\n",
    "\n",
    "for s in scenarios:\n",
    "    !python ./naive_baseline_ted.py --scenario=\"{s}\" --sub_dir=\"{s}\" -cls=\"ResNet34\" --replay_examples=150 --epochs=2 -dp=0.5 --lr=0.005\n",
    "    print('time for {}: {}'.format(s, datetime.now() - startTime))\n",
    "    \n",
    "print('total time: {}'.format(datetime.now() - startTime))\n",
    "\n",
    "# ResNet34 with 150 replay and 0.5 dropout, weight_decay=0.0001, lr=0.005 DO -> 512 -> DO -> 128 -> 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(batch_size=32, classifier='ResNet34', cuda=True, device='cuda:0', dropout=0.5, epochs=2, input_size=[3, 128, 128], lr=0.005, n_classes=50, preload_data=True, replay_examples=150, scenario='ni', sub_dir='ni')\n",
      "\n",
      "Loading data...\n",
      "Loading paths...\n",
      "Loading LUP...\n",
      "Loading labels...\n",
      "preparing CL benchmark...\n",
      "Recovering validation set...\n",
      "----------- batch 0 -------------\n",
      "x shape: (15141, 128, 128, 3), y shape: (15141,)\n",
      "Task Label:  0\n",
      "training ep:  0\n",
      "==>>> it: 0, avg. loss: 0.127305, running train acc: 0.000\n",
      "==>>> it: 100, avg. loss: 0.001220, running train acc: 0.034\n",
      "==>>> it: 200, avg. loss: 0.000542, running train acc: 0.066\n",
      "==>>> it: 300, avg. loss: 0.000302, running train acc: 0.115\n",
      "==>>> it: 400, avg. loss: 0.000212, running train acc: 0.168\n",
      "training ep:  1\n",
      "==>>> it: 0, avg. loss: 0.066709, running train acc: 0.375\n",
      "==>>> it: 100, avg. loss: 0.000605, running train acc: 0.518\n",
      "==>>> it: 200, avg. loss: 0.000195, running train acc: 0.552\n",
      "==>>> it: 300, avg. loss: 0.000101, running train acc: 0.591\n",
      "==>>> it: 400, avg. loss: 0.000082, running train acc: 0.624\n",
      "------------------------------------------\n",
      "Avg. acc: [0.3935082258781681]\n",
      "------------------------------------------\n",
      "----------- batch 1 -------------\n",
      "x shape: (15295, 128, 128, 3), y shape: (15295,)\n",
      "Task Label:  0\n",
      "training ep:  0\n",
      "==>>> it: 0, avg. loss: 0.078556, running train acc: 0.375\n",
      "==>>> it: 100, avg. loss: 0.000283, running train acc: 0.619\n",
      "==>>> it: 200, avg. loss: 0.000166, running train acc: 0.670\n",
      "==>>> it: 300, avg. loss: 0.000081, running train acc: 0.714\n",
      "==>>> it: 400, avg. loss: 0.000038, running train acc: 0.743\n",
      "training ep:  1\n",
      "==>>> it: 0, avg. loss: 0.012750, running train acc: 0.906\n",
      "==>>> it: 100, avg. loss: 0.000130, running train acc: 0.895\n",
      "==>>> it: 200, avg. loss: 0.000038, running train acc: 0.905\n",
      "==>>> it: 300, avg. loss: 0.000028, running train acc: 0.912\n",
      "==>>> it: 400, avg. loss: 0.000020, running train acc: 0.915\n",
      "------------------------------------------\n",
      "Avg. acc: [0.4899955535793686]\n",
      "------------------------------------------\n",
      "----------- batch 2 -------------\n",
      "x shape: (15436, 128, 128, 3), y shape: (15436,)\n",
      "Task Label:  0\n",
      "training ep:  0\n",
      "==>>> it: 0, avg. loss: 0.049651, running train acc: 0.469\n",
      "==>>> it: 100, avg. loss: 0.000225, running train acc: 0.753\n",
      "==>>> it: 200, avg. loss: 0.000053, running train acc: 0.805\n",
      "==>>> it: 300, avg. loss: 0.000043, running train acc: 0.835\n",
      "==>>> it: 400, avg. loss: 0.000038, running train acc: 0.854\n",
      "training ep:  1\n",
      "==>>> it: 0, avg. loss: 0.011889, running train acc: 0.875\n",
      "==>>> it: 100, avg. loss: 0.000088, running train acc: 0.943\n",
      "==>>> it: 200, avg. loss: 0.000063, running train acc: 0.946\n",
      "==>>> it: 300, avg. loss: 0.000020, running train acc: 0.952\n",
      "==>>> it: 400, avg. loss: 0.000020, running train acc: 0.954\n",
      "------------------------------------------\n",
      "Avg. acc: [0.7078701645175633]\n",
      "------------------------------------------\n",
      "----------- batch 3 -------------\n",
      "x shape: (15594, 128, 128, 3), y shape: (15594,)\n",
      "Task Label:  0\n",
      "training ep:  0\n",
      "==>>> it: 0, avg. loss: 0.048902, running train acc: 0.688\n",
      "==>>> it: 100, avg. loss: 0.000092, running train acc: 0.820\n",
      "==>>> it: 200, avg. loss: 0.000036, running train acc: 0.853\n",
      "==>>> it: 300, avg. loss: 0.000015, running train acc: 0.874\n",
      "==>>> it: 400, avg. loss: 0.000008, running train acc: 0.889\n",
      "training ep:  1\n",
      "==>>> it: 0, avg. loss: 0.002557, running train acc: 1.000\n",
      "==>>> it: 100, avg. loss: 0.000036, running train acc: 0.959\n",
      "==>>> it: 200, avg. loss: 0.000017, running train acc: 0.960\n",
      "==>>> it: 300, avg. loss: 0.000009, running train acc: 0.963\n",
      "==>>> it: 400, avg. loss: 0.000007, running train acc: 0.966\n",
      "------------------------------------------\n",
      "Avg. acc: [0.683859493108048]\n",
      "------------------------------------------\n",
      "----------- batch 4 -------------\n",
      "x shape: (15739, 128, 128, 3), y shape: (15739,)\n",
      "Task Label:  0\n",
      "training ep:  0\n",
      "==>>> it: 0, avg. loss: 0.023248, running train acc: 0.812\n",
      "==>>> it: 100, avg. loss: 0.000138, running train acc: 0.870\n",
      "==>>> it: 200, avg. loss: 0.000061, running train acc: 0.897\n",
      "==>>> it: 300, avg. loss: 0.000016, running train acc: 0.910\n",
      "==>>> it: 400, avg. loss: 0.000013, running train acc: 0.921\n",
      "training ep:  1\n",
      "==>>> it: 0, avg. loss: 0.002956, running train acc: 1.000\n",
      "==>>> it: 100, avg. loss: 0.000040, running train acc: 0.969\n",
      "==>>> it: 200, avg. loss: 0.000031, running train acc: 0.971\n",
      "==>>> it: 300, avg. loss: 0.000012, running train acc: 0.973\n",
      "==>>> it: 400, avg. loss: 0.000004, running train acc: 0.974\n",
      "------------------------------------------\n",
      "Avg. acc: [0.742996887505558]\n",
      "------------------------------------------\n",
      "----------- batch 5 -------------\n",
      "x shape: (15889, 128, 128, 3), y shape: (15889,)\n",
      "Task Label:  0\n",
      "training ep:  0\n",
      "==>>> it: 0, avg. loss: 0.047601, running train acc: 0.625\n",
      "==>>> it: 100, avg. loss: 0.000184, running train acc: 0.834\n",
      "==>>> it: 200, avg. loss: 0.000054, running train acc: 0.869\n",
      "==>>> it: 300, avg. loss: 0.000023, running train acc: 0.889\n",
      "==>>> it: 400, avg. loss: 0.000020, running train acc: 0.901\n",
      "training ep:  1\n",
      "==>>> it: 0, avg. loss: 0.007011, running train acc: 0.969\n",
      "==>>> it: 100, avg. loss: 0.000027, running train acc: 0.971\n",
      "==>>> it: 200, avg. loss: 0.000057, running train acc: 0.972\n",
      "==>>> it: 300, avg. loss: 0.000009, running train acc: 0.973\n",
      "==>>> it: 400, avg. loss: 0.000002, running train acc: 0.974\n",
      "------------------------------------------\n",
      "Avg. acc: [0.7727879057358826]\n",
      "------------------------------------------\n",
      "----------- batch 6 -------------\n",
      "x shape: (16016, 128, 128, 3), y shape: (16016,)\n",
      "Task Label:  0\n",
      "training ep:  0\n",
      "==>>> it: 0, avg. loss: 0.050475, running train acc: 0.688\n",
      "==>>> it: 100, avg. loss: 0.000153, running train acc: 0.893\n",
      "==>>> it: 200, avg. loss: 0.000010, running train acc: 0.922\n",
      "==>>> it: 300, avg. loss: 0.000005, running train acc: 0.935\n",
      "==>>> it: 400, avg. loss: 0.000008, running train acc: 0.943\n",
      "==>>> it: 500, avg. loss: 0.000028, running train acc: 0.947\n",
      "training ep:  1\n",
      "==>>> it: 0, avg. loss: 0.002896, running train acc: 1.000\n",
      "==>>> it: 100, avg. loss: 0.000013, running train acc: 0.981\n",
      "==>>> it: 200, avg. loss: 0.000013, running train acc: 0.982\n",
      "==>>> it: 300, avg. loss: 0.000003, running train acc: 0.982\n",
      "==>>> it: 400, avg. loss: 0.000009, running train acc: 0.983\n",
      "==>>> it: 500, avg. loss: 0.000015, running train acc: 0.983\n",
      "------------------------------------------\n",
      "Avg. acc: [0.7825700311249444]\n",
      "------------------------------------------\n",
      "----------- batch 7 -------------\n",
      "x shape: (16184, 128, 128, 3), y shape: (16184,)\n",
      "Task Label:  0\n",
      "training ep:  0\n",
      "==>>> it: 0, avg. loss: 0.016164, running train acc: 0.844\n",
      "==>>> it: 100, avg. loss: 0.000229, running train acc: 0.883\n",
      "==>>> it: 200, avg. loss: 0.000014, running train acc: 0.901\n",
      "==>>> it: 300, avg. loss: 0.000015, running train acc: 0.914\n",
      "==>>> it: 400, avg. loss: 0.000020, running train acc: 0.924\n",
      "==>>> it: 500, avg. loss: 0.000005, running train acc: 0.932\n",
      "training ep:  1\n",
      "==>>> it: 0, avg. loss: 0.001503, running train acc: 1.000\n",
      "==>>> it: 100, avg. loss: 0.000023, running train acc: 0.979\n",
      "==>>> it: 200, avg. loss: 0.000026, running train acc: 0.980\n",
      "==>>> it: 300, avg. loss: 0.000009, running train acc: 0.981\n",
      "==>>> it: 400, avg. loss: 0.000009, running train acc: 0.981\n",
      "==>>> it: 500, avg. loss: 0.000003, running train acc: 0.982\n",
      "------------------------------------------\n",
      "Avg. acc: [0.789239662072032]\n",
      "------------------------------------------\n",
      "Training Time: 32.06889106432597m\n",
      "Final inference on test set...\n",
      "Experiment completed.\n",
      "time for ni: 0:34:09.188096\n",
      "total time: 0:34:09.188378\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "startTime = datetime.now()\n",
    "\n",
    "# scenarios = ['ni', 'multi-task-nc', 'nic']\n",
    "scenarios = ['ni']\n",
    "\n",
    "for s in scenarios:\n",
    "    !python ./naive_baseline_ted.py --scenario=\"{s}\" --sub_dir=\"{s}\" -cls=\"ResNet34\" --replay_examples=150 --epochs=2 -dp=0.5 --lr=0.005\n",
    "    print('time for {}: {}'.format(s, datetime.now() - startTime))\n",
    "    \n",
    "print('total time: {}'.format(datetime.now() - startTime))\n",
    "\n",
    "# ResNet34 with 150 replay and 0.5 dropout, lr=0.005, weight_decay-0.0001, DO -> 512 -> DO -> 128 -> DO -> 64 -> 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6 - AzureML",
   "language": "python",
   "name": "python3-azureml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
